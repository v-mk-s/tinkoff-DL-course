{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"o12_1 DSSM.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Выводы в конце ноутбука:**"],"metadata":{"id":"mlfU2M0xPdAh"}},{"cell_type":"markdown","metadata":{"id":"UNxseYLzzvCv"},"source":["# Seminar: simple question answering\n","![img](https://recruitlook.com/wp-content/uploads/2015/01/questionanswer3.jpg)\n","\n","Today we're going to build a retrieval-based question answering model with metric learning models.\n","\n","_this seminar is based on original notebook by [Oleg Vasilev](https://github.com/Omrigan/)_\n","\n"]},{"cell_type":"code","metadata":{"id":"eUxx5lPpzvCx","executionInfo":{"status":"ok","timestamp":1644472235476,"user_tz":-180,"elapsed":10614,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn.metrics import log_loss, roc_auc_score\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from keras.preprocessing.sequence import pad_sequences"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"k5tlHnRNz1gh","outputId":"bd7b6c50-f4f5-4036-e59d-84d86fe4eb01","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472235922,"user_tz":-180,"elapsed":465,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["!wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/week11_dssm/utils.py"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-10 05:50:16--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/week11_dssm/utils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9814 (9.6K) [text/plain]\n","Saving to: ‘utils.py’\n","\n","\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]   9.58K  --.-KB/s    in 0s      \n","\n","2022-02-10 05:50:16 (60.6 MB/s) - ‘utils.py’ saved [9814/9814]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"L-Rp5Msv0BNf","outputId":"544af2c5-0c10-41b8-ebc4-f1cc0836eff5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472237612,"user_tz":-180,"elapsed":1698,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"OxgOGXMbzvC2"},"source":["### Dataset\n","\n","Today's data is Stanford Question Answering Dataset (SQuAD). Given a paragraph of text and a question, our model's task is to select a snippet that answers the question.\n","\n","We are not going to solve the full task today. Instead, we'll train a model to __select the sentence containing answer__ among several options.\n","\n","As usual, you are given an utility module with data reader and some helper functions"]},{"cell_type":"code","metadata":{"id":"US39zXJlzvC2","executionInfo":{"status":"ok","timestamp":1644472252217,"user_tz":-180,"elapsed":14614,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["import utils\n","!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad-v2.0.json 2> log\n","# backup download link: https://www.dropbox.com/s/q4fuihaerqr0itj/squad.tar.gz?dl=1\n","train, test = utils.build_dataset('./squad-v2.0.json', tokenized=True)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"pF7j-vCpzvC6","outputId":"558f641c-d82e-404f-d4ef-8533a3a0d810","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1644472252218,"user_tz":-180,"elapsed":58,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["# the data comes pre-tokenized with this simple tokenizer:\n","utils.tokenize(\"I... I'm the monument to all your sins.\")"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"i ... i ' m the monument to all your sins .\""]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"MNr15FbFzvC9","outputId":"aff4d098-710c-4290-d1f4-9a960565aec0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472252220,"user_tz":-180,"elapsed":51,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["pid, question, options, correct_indices, wrong_indices = train.iloc[40]\n","print('QUESTION', question, '\\n') # !! где-то должен быть еще текст\n","for i, cand in enumerate(options):\n","    print(['[ ]', '[v]'][i in correct_indices], cand)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["QUESTION where did beyonce get her name from ? \n","\n","[ ] beyoncé giselle knowles was born in houston , texas , to celestine ann \" tina \" knowles ( née beyincé ), a hairdresser and salon owner , and mathew knowles , a xerox sales manager .\n","[v] beyoncé ' s name is a tribute to her mother ' s maiden name .\n","[ ] beyoncé ' s younger sister solange is also a singer and a former member of destiny ' s child .\n","[ ] mathew is african - american , while tina is of louisiana creole descent ( with african , native american , french , cajun , and distant irish and spanish ancestry ).\n","[ ] through her mother , beyoncé is a descendant of acadian leader joseph broussard .\n","[ ] she was raised in a methodist household .\n"]}]},{"cell_type":"code","metadata":{"id":"cyeFnX6eDuEJ","outputId":"fdc18547-4196-47b5-c679-290c4853bc57","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472252221,"user_tz":-180,"elapsed":42,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["train['question'][:5]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0            when did beyonce start becoming popular ?\n","1    what areas did beyonce compete in when she was...\n","2    when did beyonce leave destiny ' s child and b...\n","3         in what city and state did beyonce grow up ?\n","4          in which decade did beyonce become famous ?\n","Name: question, dtype: object"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"3vvGDZJUGoZK","executionInfo":{"status":"ok","timestamp":1644472254024,"user_tz":-180,"elapsed":1838,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["words_o = [w.split() for s in train['options'].values for w in s]\n","words_o = [w for v in words_o for w in v if w not in '?\\'&,.;']"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dQ3ufZlFC18","executionInfo":{"status":"ok","timestamp":1644472254025,"user_tz":-180,"elapsed":21,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["words_q = [s.split() for s in train['question'].values]\n","words_q = [w for v in words_q for w in v if w not in '?\\'&,.;']"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sKnrxjsKzvDA"},"source":["### Tokens & vocabularies\n","\n","The procedure here is very similar to previous nlp weeks: preprocess text into tokens, create dictionaries, etc."]},{"cell_type":"code","metadata":{"id":"7Oh7zJoJzvDC","executionInfo":{"status":"ok","timestamp":1644472259920,"user_tz":-180,"elapsed":5914,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["from tqdm import tqdm, trange\n","from collections import Counter, defaultdict\n","\n","#Dictionary of {token : count}\n","words = []\n","for s in train['question']:\n","  for w in utils.tokenize(s).split():\n","    words.append(w)\n","    \n","for b in train['options']:\n","  for s in b: \n","    for w in utils.tokenize(s).split():\n","      words.append(w)\n","# compute counts for each token; use token_counts;\n","# count BOTH in train['question'] and in train['options']"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"WUt1CTEGIhBt","executionInfo":{"status":"ok","timestamp":1644472260248,"user_tz":-180,"elapsed":35,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["token_counts = Counter(words)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"miZzEh1UzvDG","outputId":"f8fc0a7d-4cd8-4edc-83b3-39fa8932c7de","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472260250,"user_tz":-180,"elapsed":35,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["print(\"Total tokens:\", sum(token_counts.values()))\n","print(\"Most common:\", token_counts.most_common(5))\n","assert 9000000 < sum(token_counts.values()) < 9100000, \"are you sure you counted all unique tokens in questions and options?\""],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Total tokens: 9042915\n","Most common: [('the', 597790), (',', 438053), ('.', 304508), ('of', 300056), ('and', 231619)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"mlw19UFFzvDJ"},"source":["We shall only keep tokens that are present at least 4 times"]},{"cell_type":"code","metadata":{"id":"aNvC_4tDzvDK","outputId":"f7390e88-c3b2-49ae-c4f7-ff804aa4561f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472260251,"user_tz":-180,"elapsed":32,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["MIN_COUNT = 5\n","\n","tokens = [w for w, c in token_counts.items() if c >= MIN_COUNT] \n","tokens = [\"_PAD_\", \"_UNK_\"] + tokens\n","print(\"Tokens left:\", len(tokens))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens left: 55940\n"]}]},{"cell_type":"code","metadata":{"id":"A9NK0qpRzvDM","executionInfo":{"status":"ok","timestamp":1644472260252,"user_tz":-180,"elapsed":27,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["# a dictionary from token to it's index in tokens\n","token_to_id = {t:i for i,t in enumerate(tokens)}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"bAWawL47zvDP","executionInfo":{"status":"ok","timestamp":1644472260254,"user_tz":-180,"elapsed":28,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["assert token_to_id['me'] != token_to_id['woods']\n","assert token_to_id[tokens[42]]==42\n","assert len(token_to_id)==len(tokens)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Xn5NzZ0zvDS","executionInfo":{"status":"ok","timestamp":1644472260255,"user_tz":-180,"elapsed":28,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["PAD_ix = token_to_id[\"_PAD_\"]\n","UNK_ix = token_to_id['_UNK_']\n","\n","#good old as_matrix for the third time\n","def as_matrix(sequences, max_len=None):\n","    if isinstance(sequences[0], (str, bytes)):\n","        sequences = [utils.tokenize(s).split() for s in sequences]\n","        \n","    max_len = max_len or max(map(len,sequences))\n","    \n","    matrix = np.zeros((len(sequences), max_len), dtype='int32') + PAD_ix\n","    for i, seq in enumerate(sequences):\n","        row_ix = [token_to_id.get(word, UNK_ix) for word in seq[:max_len]]\n","        matrix[i, :len(row_ix)] = row_ix\n","    \n","    return matrix"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"wK25QWBNzvDV","outputId":"943820dd-2198-4893-ab26-76e7a77601d9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472260537,"user_tz":-180,"elapsed":309,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["test = as_matrix([\"Definitely, thOsE tokens areN'T LowerCASE!!\", \"I'm the monument to all your sins.\"])\n","print(test)\n","# assert test.shape==(2,8)\n","print(\"Correct!\")"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[11406    69  2010  7828  7504    19   977 12465     1     0]\n"," [  197    19  2538    37  6879    49   652  6306 25055   340]]\n","Correct!\n"]}]},{"cell_type":"markdown","metadata":{"id":"T058hedOzvDX"},"source":["### Data sampler\n","\n","Our model trains on triplets: $<query, answer^+, answer^->$\n","\n","For your convenience, we've implemented a function that samples such triplets from data"]},{"cell_type":"code","metadata":{"id":"Eg4xlH_6zvDX","executionInfo":{"status":"ok","timestamp":1644472260539,"user_tz":-180,"elapsed":30,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["import random\n","import torch\n","lines_to_tensor = lambda lines, max_len=None: torch.tensor(\n","    as_matrix(lines, max_len=max_len), dtype=torch.int64)\n","\n","def iterate_minibatches(data, batch_size, shuffle=True, cycle=False):\n","    \"\"\"\n","    Generates minibatches of triples: {questions, correct answers, wrong answers}\n","    If there are several wrong (or correct) answers, picks one at random.\n","    \"\"\"\n","    indices = np.arange(len(data))\n","    while True:\n","        if shuffle:\n","            indices = np.random.permutation(indices)\n","        for batch_start in range(0, len(indices), batch_size):\n","            batch_indices = indices[batch_start: batch_start + batch_size]\n","            batch = data.iloc[batch_indices]\n","            questions = batch['question'].values\n","            correct_answers = np.array([\n","                row['options'][random.choice(row['correct_indices'])]\n","                for i, row in batch.iterrows()\n","            ])\n","            wrong_answers = np.array([\n","                row['options'][random.choice(row['wrong_indices'])]\n","                for i, row in batch.iterrows()\n","            ])\n","\n","            yield {\n","                'questions' : lines_to_tensor(questions),\n","                'correct_answers': lines_to_tensor(correct_answers),\n","                'wrong_answers': lines_to_tensor(wrong_answers),\n","            }\n","        if not cycle:\n","            break"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"KuWxum9izvDZ","outputId":"80585b16-3866-482d-c7bd-f51bbfb77265","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472260540,"user_tz":-180,"elapsed":30,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["dummy_batch = next(iterate_minibatches(train.sample(2), 3))\n","print(dummy_batch)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["{'questions': tensor([[    9, 11413,   507,  2915,   777,    49,  1038,   326,    37,  2627,\n","         13526,    22,   307, 13565,     8],\n","        [  163,     3,  2911, 17459,  1930,    55,    24,  2131,     1,     8,\n","             0,     0,     0,     0,     0]]), 'correct_answers': tensor([[ 2915,    22,  3985,  4476,    66, 14053,   350,  1177,    83,   108,\n","          1840,    22,  2942,  4276,  6136,   535, 13564,  4277,   598,  7306,\n","           332,  4416, 36546,    37,  4998,   245,    37,  2358,  3910,    22,\n","          4604,   428,   100, 13566, 11413,    49,  1038,   326,    37,  2627,\n","         13526,    22,   307, 13565,   839,    37,  2363,    64, 36486, 11851,\n","           340],\n","        [ 2911, 17459,    69,    24,  2131,  7325,   207,     1,   754,    69,\n","           159,   785,   482,   255,    37,  4031,  1070,    66,  2328,  2104,\n","           111,  6145,    49,    37,   968,    66,  8071,    69,  9402,   115,\n","            86,    66,    37,  2388,    19,  1995,    69,    22,   482,  6966,\n","            24,  2252,  4152,    49,    37,   460,  6045,    64,  2301,  4031,\n","          5971]]), 'wrong_answers': tensor([[  436,   159,   147,    37,  3476,    66, 15629,    37,  2174,  2926,\n","           710,    90,    37,   924,   710,   340,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0],\n","        [   37,  2340,   249,   604,  4192,   161, 41058,     1,    69,    45,\n","           785,   482,  2171,  2108,  2070,  7996,   255, 10984,  2032,  2301,\n","           255,   482,  2070,   320,  1017,    49,   255,  5121,    37,  2203,\n","            22,  1288,    66,  8745,   460,  5733,    22,  1264, 10198,    22,\n","          6649,   482,   463,  6209,  2062,   332,  9322,     1,    69,    37,\n","           339,   340,    20,   340,  1472,   519,   171,   161,  8071,    49,\n","          2175, 30115,  2301,   340]])}\n"]}]},{"cell_type":"code","source":["# !pip install deepctr_torch"],"metadata":{"id":"LQhSZ3ttRYEb","executionInfo":{"status":"ok","timestamp":1644472260542,"user_tz":-180,"elapsed":27,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# from deepctr_torch.inputs import SparseFeat, DenseFeat, VarLenSparseFeat"],"metadata":{"id":"eTH8CuXHRXXL","executionInfo":{"status":"ok","timestamp":1644472260543,"user_tz":-180,"elapsed":27,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iBHPzOdZzvDb"},"source":["### Building the model (3 points)\n","\n","Our goal for today is to build a model that measures similarity between question and answer. In particular, it maps both question and answer into fixed-size vectors such that:\n","\n","Our model is a pair of $V_q(q)$ and $V_a(a)$ - networks that turn phrases into vectors. \n","\n","__Objective:__ Question vector $V_q(q)$ should be __closer__ to correct answer vectors $V_a(a^+)$ than to incorrect ones $V_a(a^-)$ .\n","\n","Both vectorizers can be anything you wish. For starters, let's use a convolutional network with global pooling and a couple of dense layers on top.\n","\n","It is perfectly legal to share some layers between vectorizers, but make sure they are at least a little different."]},{"cell_type":"code","metadata":{"id":"HItbkJWNzvDc","executionInfo":{"status":"ok","timestamp":1644472260544,"user_tz":-180,"elapsed":28,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["import torch, torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","class GlobalMaxPooling(nn.Module):\n","    def __init__(self, dim=-1):\n","        super(self.__class__, self).__init__()\n","        self.dim = dim\n","        \n","    def forward(self, x):\n","        return x.max(dim=self.dim)[0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dOYRxYlzvDd","executionInfo":{"status":"ok","timestamp":1644472260546,"user_tz":-180,"elapsed":29,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["# we might as well create a global embedding layer here\n","\n","GLOBAL_EMB = nn.Embedding(len(tokens), 64, padding_idx=PAD_ix)"],"execution_count":23,"outputs":[]},{"cell_type":"code","source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        # num_embedding = vocab_size_fra\n","        self.embedder = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size) # dim1, dim2\n","\n","    def forward(self, input, hidden):\n","        # (batch_size, num_words) -> (batch_size, num_words, dim_1)\n","        embeddings = self.embedder(input).view(1, 1, -1)\n","        # (batch_size, num_words, dim_2)\n","        output, hidden = self.gru(embeddings, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"metadata":{"id":"i-MYYEXUWat5","executionInfo":{"status":"ok","timestamp":1644472260547,"user_tz":-180,"elapsed":29,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["min_len = 40  # предложения с меньшим количеством символов не будут рассматриваться\n","max_len = 150 # предложения с большим количеством символов будут обрезаться"],"metadata":{"id":"qoYbqoK2bNb3","executionInfo":{"status":"ok","timestamp":1644472260549,"user_tz":-180,"elapsed":30,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class QuestionVectorizer2(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","    def forward(self, src):\n","        # src : [sen_len, batch_size]\n","        embedded = self.dropout(self.embedding(src))\n","        \n","        # embedded : [sen_len, batch_size, emb_dim]\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        # outputs = [sen_len, batch_size, hid_dim * n_directions]\n","        # hidden = [n_layers * n_direction, batch_size, hid_dim]\n","        # cell = [n_layers * n_direction, batch_size, hid_dim]\n","        return hidden, cell"],"metadata":{"id":"F9sdUKSBVXJy"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aO0LtQmUzvDf","executionInfo":{"status":"ok","timestamp":1644472260550,"user_tz":-180,"elapsed":29,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["class QuestionVectorizer(nn.Module):\n","    def __init__(self, n_tokens=len(tokens), out_size=64, use_global_emb=True, hidden_size=64, batch_size = 32):\n","        \"\"\" \n","        A simple sequential encoder for questions.\n","        Use any combination of layers you want to encode a variable-length input \n","        to a fixed-size output vector\n","        \n","        If use_global_emb is True, use GLOBAL_EMB as your embedding layer\n","        \"\"\"\n","        super(self.__class__, self).__init__()\n","     \n","        self.n_tokens = n_tokens\n","        self.hidden_size = hidden_size\n","        self.out_size = out_size\n","        self.batch_size = batch_size\n","\n","        if use_global_emb:\n","            self.emb = GLOBAL_EMB\n","        else:\n","            self.emb = nn.Embedding(n_tokens, 64, padding_idx=PAD_ix)\n","            \n","        \n","        self.rnn = torch.nn.GRU(hidden_size, out_size)\n","\n","    def forward(self, text_ix):\n","        \"\"\"\n","        :param text_ix: int64 Variable of shape [batch_size, max_len]\n","        :returns: float32 Variable of shape [batch_size, out_size]\n","        \"\"\"\n","        emb = self.emb(text_ix)\n","        \n","        hidden = self.init_hidden(text_ix.shape)\n","        # print(text_ix.shape, emb.shape, hidden.shape)\n","        output, hidden = self.rnn(emb, hidden)\n","        return output, hidden\n","\n","    def init_hidden(self, hidden_size):\n","        #print(hidden_size)\n","        return torch.zeros(1, hidden_size[1], self.out_size) # self.batch_size"],"execution_count":26,"outputs":[]},{"cell_type":"code","source":["text_ix = dummy_batch['questions']"],"metadata":{"id":"AHI9kUqdasP0","executionInfo":{"status":"ok","timestamp":1644472260552,"user_tz":-180,"elapsed":30,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"JlcobjCcfvro","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472261028,"user_tz":-180,"elapsed":506,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}},"outputId":"7105183b-1fbe-48e1-87e4-9e127f25d8b6"},"source":["q = QuestionVectorizer(n_tokens=len(tokens), out_size=64, use_global_emb=True, batch_size=2, hidden_size=64)\n","q.forward(text_ix)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[-0.0429, -0.2146, -0.2155,  ..., -0.3599,  0.3684,  0.0540],\n","          [-0.2025, -0.2482, -0.0260,  ...,  0.1194, -0.0978, -0.2387],\n","          [ 0.1182, -0.3729,  0.1004,  ...,  0.1361, -0.0398,  0.2033],\n","          ...,\n","          [ 0.2057, -0.2376, -0.4203,  ...,  0.1543, -0.0114,  0.0311],\n","          [-0.4793,  0.2932, -0.0450,  ...,  0.0253, -0.3619,  0.3519],\n","          [-0.1921, -0.0954, -0.2364,  ..., -0.0086,  0.0055, -0.5748]],\n"," \n","         [[-0.4772, -0.2793, -0.1564,  ...,  0.0118,  0.4160,  0.0244],\n","          [-0.5501,  0.2735,  0.1094,  ...,  0.3052, -0.0175, -0.2757],\n","          [ 0.0398, -0.1544,  0.0931,  ..., -0.2236,  0.3561, -0.4248],\n","          ...,\n","          [ 0.0285, -0.0603, -0.1965,  ...,  0.0502, -0.0306,  0.0064],\n","          [-0.3490,  0.1779, -0.0896,  ...,  0.0219, -0.2664,  0.0746],\n","          [-0.1611,  0.0215, -0.1424,  ...,  0.0317, -0.0079, -0.3733]]],\n","        grad_fn=<StackBackward0>),\n"," tensor([[[-4.7717e-01, -2.7927e-01, -1.5641e-01,  4.4366e-02,  2.6702e-01,\n","           -2.7007e-01, -2.2083e-01, -5.1539e-01, -2.4755e-01,  2.7467e-01,\n","           -1.6499e-01,  2.9307e-01, -2.6295e-01,  2.4687e-01, -2.1278e-01,\n","            1.7268e-01, -2.2571e-01,  1.1307e-01,  1.2191e-01,  8.4511e-02,\n","           -1.9142e-01, -4.3692e-01,  3.5444e-01, -1.9595e-01, -1.4612e-02,\n","           -2.9334e-02, -9.5081e-02, -8.3345e-02,  1.1235e-01,  7.7090e-02,\n","           -1.2106e-01,  5.2450e-01, -5.7562e-02,  5.8247e-02, -1.9478e-01,\n","            1.8511e-01, -1.2428e-01,  8.8116e-02,  8.7584e-02, -1.7609e-01,\n","           -4.6202e-01, -3.1683e-01, -7.4659e-02, -1.0269e-01,  5.5280e-01,\n","            1.3012e-02,  3.1112e-01,  4.5689e-01, -3.5276e-01,  4.4026e-02,\n","            5.8554e-02,  2.2052e-01,  4.0412e-01,  2.7442e-01,  2.9536e-01,\n","            2.7218e-01,  4.2515e-01, -3.9221e-01, -2.3176e-01, -3.3843e-02,\n","           -1.9176e-02,  1.1797e-02,  4.1596e-01,  2.4384e-02],\n","          [-5.5012e-01,  2.7349e-01,  1.0941e-01, -2.6270e-01, -2.8880e-01,\n","           -4.4712e-01,  4.6535e-01, -2.4188e-02, -1.3591e-01,  3.1452e-01,\n","           -4.2569e-01, -4.3197e-01, -1.4141e-02, -2.6121e-01,  1.9484e-01,\n","           -3.6727e-03, -1.6181e-01, -1.1473e-01,  3.3786e-01,  2.8046e-01,\n","            3.0337e-01,  5.3568e-01,  2.9324e-01,  2.4765e-01,  1.6056e-01,\n","           -2.7753e-01,  3.8411e-02, -2.1398e-01,  1.3217e-01,  2.3920e-01,\n","            1.7177e-01, -8.8928e-02,  4.7396e-01, -3.3735e-01, -6.0865e-02,\n","            2.0800e-01, -6.4688e-02,  3.4615e-03, -2.2845e-01,  3.9771e-01,\n","            5.1549e-01, -4.1260e-01, -3.1770e-02,  6.2583e-01, -3.0195e-01,\n","            1.6579e-01, -3.5266e-02, -4.3142e-02, -2.8336e-01, -3.7186e-02,\n","            8.5538e-02,  8.8142e-03, -1.6539e-01, -7.3800e-02,  1.9401e-01,\n","            1.4816e-01, -9.3111e-02,  5.9691e-02, -1.2609e-01,  2.2935e-01,\n","            1.6568e-01,  3.0525e-01, -1.7518e-02, -2.7570e-01],\n","          [ 3.9777e-02, -1.5439e-01,  9.3108e-02,  6.0900e-01, -1.1769e-01,\n","            3.0321e-01, -8.5689e-02, -5.1974e-01,  3.8942e-01,  2.3751e-02,\n","            1.5119e-01, -9.5917e-02,  2.8390e-01, -6.4290e-01,  2.8095e-02,\n","           -3.4912e-02,  2.5939e-01,  2.5502e-02,  4.7822e-01, -1.7868e-01,\n","           -4.1460e-02,  8.4170e-02,  2.0212e-01, -1.5224e-01,  7.0824e-02,\n","            8.9448e-02,  7.3724e-01,  1.9647e-01, -9.2280e-02, -3.5876e-01,\n","            1.7375e-01,  1.5939e-01,  3.1685e-01, -3.4692e-01, -3.3992e-01,\n","           -1.1440e-01, -5.7076e-01,  3.0662e-01, -1.9895e-01, -2.2028e-01,\n","            6.8114e-02, -3.6676e-02, -3.5163e-01, -2.9867e-01,  3.7134e-03,\n","           -3.0511e-01,  2.2882e-01, -2.9577e-01, -3.1077e-01, -1.9140e-01,\n","            1.8910e-01,  3.4944e-01, -2.3808e-01,  2.5429e-01,  7.9537e-02,\n","            1.1893e-02, -1.6477e-01, -8.8190e-02, -1.9079e-01, -7.1198e-02,\n","            6.0239e-01, -2.2356e-01,  3.5612e-01, -4.2475e-01],\n","          [-2.2426e-01, -9.7841e-02, -4.8018e-01, -4.6802e-01,  1.3435e-01,\n","            5.5645e-02, -5.4295e-01,  2.2993e-01,  2.4294e-01, -4.3251e-02,\n","           -5.4243e-02, -7.2534e-02, -2.7759e-01, -3.1805e-01,  2.7002e-01,\n","           -6.4524e-02,  4.0880e-02,  1.9018e-01, -5.5601e-02, -6.2679e-01,\n","           -1.4116e-01,  2.5921e-01, -7.2367e-03,  3.0762e-01, -1.1612e-01,\n","            6.0750e-01,  2.7577e-01,  2.0006e-01, -1.5669e-01, -8.5974e-02,\n","           -1.7728e-01,  3.3975e-01,  1.9390e-01, -1.6964e-02, -2.4294e-01,\n","           -3.4342e-01,  2.7206e-01, -1.0795e-01, -9.6110e-02, -1.6604e-01,\n","           -1.4570e-01, -7.8143e-02, -3.0552e-01,  1.8004e-01,  4.5583e-01,\n","            1.8020e-01,  5.8096e-02, -1.3470e-01, -1.7693e-01, -2.6934e-01,\n","           -3.4687e-01, -2.9997e-01,  4.4000e-02,  2.7420e-01, -2.4406e-01,\n","            2.7609e-01,  7.4946e-02, -1.1243e-01,  3.0933e-03,  6.9520e-01,\n","           -4.4761e-01,  2.9297e-02, -8.1663e-02, -4.7042e-01],\n","          [-2.1267e-01,  2.2589e-01,  1.1895e-01, -5.4075e-01,  9.7528e-02,\n","           -3.0821e-01,  1.1397e-01,  9.7726e-02,  8.3459e-02,  2.5564e-01,\n","           -4.3532e-01,  2.7668e-01, -7.8603e-02, -1.8754e-01, -1.8056e-02,\n","            2.4817e-01, -1.2748e-01,  3.5294e-01, -1.4287e-01,  3.9557e-01,\n","            3.4170e-01,  4.5458e-01, -1.1656e-01, -1.5654e-01,  3.1114e-02,\n","            6.1516e-02,  3.7382e-01, -3.2318e-01,  9.7296e-02,  1.4516e-01,\n","           -3.8697e-01,  1.4955e-01, -7.4155e-02, -4.0079e-01,  3.8716e-02,\n","            4.6149e-02, -4.6660e-01, -8.8293e-02, -5.9080e-02, -1.8603e-01,\n","           -1.8547e-01,  1.6378e-01, -3.9106e-01, -1.4925e-01, -2.9704e-02,\n","            1.2271e-01,  1.8644e-02,  1.1702e-01,  3.6512e-01, -3.0309e-01,\n","           -4.0604e-01, -2.9860e-01, -4.6870e-01, -7.0650e-02, -2.2180e-01,\n","            2.5126e-02,  1.4967e-01, -5.8055e-02, -2.5493e-01,  3.8703e-01,\n","           -7.3270e-02, -5.5195e-02,  3.8101e-01,  7.5756e-02],\n","          [ 3.4699e-02, -6.0294e-01,  9.1251e-02, -1.7119e-01, -6.2158e-02,\n","           -4.6086e-01, -3.2097e-01,  3.2808e-01,  5.2255e-02, -4.9474e-02,\n","            2.0153e-01, -2.2462e-01, -4.2285e-01, -1.9284e-01, -3.9467e-01,\n","           -1.9188e-01, -3.7042e-02,  5.1523e-01, -2.8272e-01, -6.0086e-01,\n","            3.4648e-02,  5.7095e-01,  4.8430e-01, -9.0167e-02,  4.6813e-01,\n","            1.7684e-01, -1.6085e-02,  2.1704e-01, -2.6747e-01, -5.3056e-01,\n","           -5.8647e-02,  1.3361e-01, -2.3530e-01, -1.6040e-01,  1.9666e-01,\n","           -1.2188e-01, -1.5035e-01, -3.0168e-01,  3.4573e-01, -7.5201e-02,\n","           -2.4087e-01, -1.7582e-01, -3.0123e-01, -1.7139e-01, -3.3413e-01,\n","            3.7911e-02,  5.6475e-01, -2.5392e-01,  2.4606e-02, -3.1771e-01,\n","            1.7767e-01,  1.7762e-01, -5.8418e-01,  3.9241e-02, -2.4970e-01,\n","            2.2871e-01, -3.9641e-01,  1.5791e-01,  1.5384e-01, -1.8538e-01,\n","            3.8827e-01, -2.5963e-02,  5.8971e-02, -1.7170e-01],\n","          [-4.8951e-01, -2.3391e-02,  3.3969e-01, -7.5510e-02,  1.8875e-01,\n","            2.7445e-01,  9.3501e-02, -4.3952e-01,  3.8155e-01,  1.9341e-01,\n","           -1.7718e-01,  3.6993e-01,  3.0768e-01, -2.5376e-01,  3.6918e-01,\n","           -3.7877e-01,  1.3794e-02,  2.9601e-01, -4.1677e-01,  2.7894e-01,\n","            7.6404e-02,  2.4232e-01, -2.5907e-01,  6.0102e-02, -1.6056e-01,\n","            3.3003e-01,  5.5812e-01,  7.1042e-02, -6.3344e-01,  4.3585e-01,\n","           -2.5978e-02, -2.6181e-01,  2.5834e-01, -2.2000e-01, -3.7584e-01,\n","            5.0658e-01,  9.9032e-02, -4.1073e-01, -1.7963e-01, -3.4391e-01,\n","            1.3709e-01, -6.3568e-04, -4.7604e-02,  2.2043e-01, -4.8976e-02,\n","           -4.5203e-01, -3.0877e-01,  3.9734e-01,  2.4316e-01, -3.9111e-01,\n","           -2.9690e-01,  2.6039e-02, -4.8080e-01,  4.0422e-01, -2.0779e-01,\n","            8.3593e-02, -1.5286e-02, -2.0563e-01, -1.7915e-01,  1.3822e-02,\n","            2.8452e-01, -2.7558e-01,  2.9129e-02,  1.0892e-01],\n","          [ 2.0691e-01, -5.0551e-01,  1.2576e-02,  2.6678e-01,  2.6868e-01,\n","           -9.2680e-02,  3.9037e-02, -2.8883e-01,  5.6798e-01, -9.7751e-02,\n","           -4.2472e-01,  1.1580e-01, -4.4572e-01,  6.7655e-01,  6.3379e-02,\n","            3.6133e-01, -1.1207e-01, -6.4738e-01,  8.5656e-02, -9.2974e-02,\n","           -4.0876e-01, -1.3247e-01,  7.0961e-02, -2.8905e-01,  4.5027e-02,\n","           -9.8339e-02, -1.5767e-01, -8.2578e-02, -7.2438e-02, -1.5150e-02,\n","            5.1020e-01, -1.1486e-01,  1.1616e-01, -3.2393e-01,  2.3954e-01,\n","            1.7121e-01, -7.2737e-01, -2.3851e-01, -3.0824e-01, -1.9333e-01,\n","           -6.5388e-01,  1.9286e-01, -5.3485e-01, -7.2541e-02,  2.3011e-01,\n","           -6.3225e-01, -1.3371e-01,  9.6941e-02, -3.8523e-01,  6.3255e-01,\n","           -2.2567e-01, -1.6969e-02, -5.1182e-01,  1.5875e-01,  1.3997e-01,\n","           -1.3075e-01, -2.4509e-01, -7.3922e-02,  3.7895e-02,  5.6458e-01,\n","            2.2471e-02,  1.6585e-01, -4.6567e-01, -4.7311e-01],\n","          [ 6.3680e-02,  2.7850e-01,  2.0405e-02,  2.3910e-01,  1.8997e-01,\n","            1.2682e-02, -3.6379e-01, -2.9489e-01,  7.0297e-02,  1.9374e-01,\n","            3.3268e-01,  1.0437e-01, -6.4714e-01,  3.6953e-03,  3.5204e-01,\n","            2.6353e-02,  6.2803e-02,  6.4434e-01,  4.7786e-01, -2.9390e-01,\n","            1.0423e-01,  1.3178e-01,  1.8379e-03,  4.3250e-01, -2.3833e-01,\n","           -2.0480e-01,  1.6962e-01, -3.4556e-02,  5.2710e-03,  6.0678e-02,\n","           -6.1543e-02, -3.0298e-01,  3.1777e-01, -5.4816e-01,  1.0977e-02,\n","           -7.2668e-02, -6.4904e-01,  6.3101e-02,  2.3766e-01, -3.5207e-01,\n","           -3.0940e-01, -4.0184e-01, -2.8497e-01,  2.4642e-01,  2.0723e-02,\n","           -7.4665e-03,  1.9773e-01, -7.4625e-02, -2.4217e-01, -9.6944e-02,\n","            3.2245e-01,  2.0971e-01, -5.8493e-01,  2.9347e-02, -3.8422e-01,\n","            2.4314e-01, -5.1002e-01,  2.7635e-01, -2.9562e-01, -1.0389e-01,\n","           -2.2230e-02,  3.3750e-01, -1.1079e-01, -6.1882e-01],\n","          [-2.8615e-01, -1.2301e-01, -3.5882e-01,  8.0749e-02, -2.3575e-01,\n","            2.4863e-01,  7.3516e-02,  6.8214e-02,  2.8225e-01,  7.0152e-02,\n","           -1.2205e-01, -2.8205e-02, -2.0319e-01, -9.5047e-02,  1.1008e-01,\n","           -2.5077e-01,  4.3876e-01,  1.7360e-01, -2.1894e-01,  1.0919e-01,\n","            3.2767e-02, -1.1144e-01, -2.4447e-01, -2.8215e-01,  2.0671e-01,\n","           -6.6923e-02,  4.6305e-01,  7.2201e-03,  7.0271e-02, -3.7631e-01,\n","           -4.6744e-02,  8.0428e-02, -5.8789e-02,  2.1501e-01, -5.4679e-02,\n","            5.9816e-02, -5.3930e-01,  1.1034e-01, -2.7405e-01,  4.3045e-01,\n","            1.4507e-01, -3.7731e-03,  1.5862e-01, -1.0858e-01, -1.8513e-01,\n","           -3.1126e-01,  2.8670e-01, -1.2379e-01, -3.7218e-02, -2.1262e-01,\n","           -9.0965e-02, -5.2198e-01, -5.7450e-01,  1.3597e-01, -4.9155e-01,\n","           -3.3584e-01, -3.2345e-01, -1.4990e-01, -3.8346e-01, -2.7209e-02,\n","            2.8246e-02, -2.7032e-01, -3.0021e-01, -6.9839e-01],\n","          [-2.5316e-01, -3.9101e-02, -1.6808e-01, -1.2639e-01,  5.3409e-02,\n","            1.9624e-01, -1.7238e-02,  1.5352e-02,  1.9238e-01,  7.1124e-02,\n","            7.9774e-02, -1.6421e-03,  1.2852e-01,  3.1139e-02, -1.4655e-01,\n","            1.3546e-01, -1.6293e-01, -1.1879e-01, -1.4935e-01, -8.7679e-02,\n","            1.0438e-01, -1.6747e-01,  4.2156e-02,  1.1234e-01, -1.3049e-02,\n","            8.2628e-02,  1.4711e-01, -1.2677e-01, -6.6369e-02, -1.0098e-02,\n","           -1.1813e-01, -1.1460e-01, -5.2107e-02,  1.4827e-01,  1.9568e-01,\n","            1.2850e-01, -2.0461e-02,  4.2932e-02,  1.6118e-01,  1.0054e-01,\n","           -3.7491e-03,  3.4928e-02, -1.5424e-01,  2.0054e-01,  1.8916e-01,\n","           -1.4489e-02, -5.4709e-02,  9.2228e-02, -1.5094e-01, -9.0972e-02,\n","           -8.2449e-02, -4.4596e-03,  7.9065e-02,  8.9893e-02,  3.5111e-02,\n","            2.2629e-02, -7.5728e-02, -2.4288e-01,  6.0303e-02,  1.4938e-01,\n","           -3.7642e-02,  7.8066e-02, -2.4002e-02, -3.7239e-02],\n","          [-2.9054e-01,  4.3339e-02, -6.6360e-02, -1.4494e-01, -2.5025e-02,\n","            1.9256e-01, -1.0469e-01, -2.8416e-01,  2.0571e-02, -1.9404e-02,\n","            1.2928e-01,  1.9696e-02,  2.8532e-02,  1.9386e-01, -3.3277e-02,\n","            1.3554e-01,  4.8755e-02,  1.6699e-01, -1.2965e-03, -9.7362e-02,\n","            1.7795e-01, -1.1171e-01, -6.9932e-02,  1.0316e-01,  4.0341e-02,\n","           -1.4001e-01,  2.0726e-01, -2.5013e-01, -5.4527e-02,  1.1155e-01,\n","           -3.9501e-02,  5.5099e-02, -2.2173e-01,  2.9617e-02,  5.4961e-04,\n","            1.3839e-01,  5.5150e-02, -7.2233e-02,  3.5178e-01, -1.8698e-01,\n","            5.4813e-02, -1.3950e-01,  1.7390e-01,  1.0465e-01, -4.2840e-03,\n","           -1.0652e-01,  3.0774e-04,  6.8204e-02, -5.3484e-02, -1.3602e-01,\n","           -9.4626e-03, -9.6574e-02,  2.0949e-01,  1.2974e-01, -4.4198e-02,\n","           -5.8606e-02,  7.6045e-02,  1.8129e-01, -9.0031e-02,  8.5975e-02,\n","            9.3622e-02,  7.7281e-02, -6.3691e-02,  4.9488e-02],\n","          [ 2.8476e-02, -6.0296e-02, -1.9654e-01, -6.0145e-02, -1.8535e-01,\n","            2.7032e-01,  1.5831e-01,  1.3048e-01,  1.0050e-01,  2.5173e-01,\n","           -2.1158e-02, -9.9406e-02,  9.1299e-02,  8.2673e-02, -2.7884e-01,\n","           -1.2785e-01, -3.7015e-02, -1.0365e-01, -1.7018e-01,  8.3789e-02,\n","            5.1027e-02, -1.1919e-01, -2.4014e-02, -6.9174e-02,  2.6428e-01,\n","            1.0153e-01,  1.7968e-01, -6.0091e-02,  3.7678e-04, -5.8087e-02,\n","            1.1190e-01, -2.3446e-01, -9.7331e-02,  1.3620e-01, -1.9844e-01,\n","            8.5829e-02, -7.0852e-02,  1.1372e-01,  9.1024e-02,  6.7058e-02,\n","            6.7301e-02, -6.1039e-03, -1.4858e-01, -5.3718e-02, -1.3023e-01,\n","           -1.7259e-01, -3.9603e-02, -9.8424e-03, -5.0727e-03, -2.6564e-01,\n","           -1.5587e-01,  6.3091e-03, -3.0911e-02,  1.0688e-01, -2.0265e-01,\n","           -1.8627e-01,  8.9083e-02, -1.2118e-01,  9.0601e-02, -1.3350e-01,\n","            1.8294e-01,  5.0210e-02, -3.0595e-02,  6.3516e-03],\n","          [-3.4900e-01,  1.7794e-01, -8.9574e-02, -2.0390e-01, -1.9441e-02,\n","            1.4891e-01,  1.0874e-01, -4.4969e-02,  1.2655e-01,  7.6632e-02,\n","            6.4265e-02, -9.3445e-02,  9.9508e-02, -3.8273e-02,  5.5825e-02,\n","           -8.9754e-02, -8.8209e-02, -1.9391e-01,  1.8467e-01,  7.5259e-02,\n","           -1.5376e-01,  2.3150e-01, -2.3276e-01, -3.1769e-02,  1.3528e-01,\n","           -4.0234e-02,  7.2761e-02, -8.6314e-02,  9.2598e-02,  1.9135e-02,\n","           -1.5288e-01,  2.5771e-01, -6.9845e-02, -6.1743e-02, -3.8777e-02,\n","            4.0813e-03,  1.3514e-01,  1.1558e-01,  1.5377e-01,  2.3245e-02,\n","           -8.6560e-02,  4.6646e-02,  2.0325e-01,  1.0228e-01, -4.5169e-02,\n","           -3.6487e-02,  1.2234e-01, -2.7619e-01, -3.2421e-02,  1.6069e-02,\n","           -2.8239e-01,  7.1498e-02,  2.2146e-02,  7.3036e-02,  1.0553e-01,\n","            1.0193e-01,  2.0701e-01, -2.6726e-01, -1.1947e-01, -5.0839e-02,\n","            1.2779e-01,  2.1917e-02, -2.6645e-01,  7.4587e-02],\n","          [-1.6110e-01,  2.1536e-02, -1.4245e-01,  6.5567e-02, -1.9112e-01,\n","            1.3246e-01,  1.6068e-04,  2.9735e-03,  1.0818e-01,  1.2582e-02,\n","           -6.4713e-02, -5.6329e-02, -6.1531e-02, -8.2589e-03,  1.6290e-01,\n","           -1.5030e-01,  2.7120e-01,  1.4351e-01, -1.0720e-01,  4.1478e-02,\n","           -8.4702e-03,  5.1482e-02, -2.1505e-02, -1.1097e-02,  6.4313e-02,\n","            1.8466e-02,  2.1842e-01,  5.5432e-02,  2.0321e-02, -1.1171e-01,\n","           -3.5219e-02, -2.8277e-02, -2.8192e-02,  4.8982e-02, -1.0134e-01,\n","            1.5122e-01, -1.9572e-01,  1.3239e-01, -1.1295e-01,  1.3462e-01,\n","            6.4609e-02, -2.4486e-02, -6.0380e-02,  2.9362e-02, -8.4236e-02,\n","           -1.9700e-01,  3.4036e-02, -9.1265e-02, -9.9538e-02, -1.1589e-01,\n","           -1.2350e-01, -4.8840e-02, -2.3507e-01,  4.3965e-02, -1.5452e-01,\n","           -9.6660e-02, -3.3959e-02, -7.0138e-02, -1.3496e-01, -9.9952e-02,\n","            3.5742e-03,  3.1710e-02, -7.9142e-03, -3.7328e-01]]],\n","        grad_fn=<StackBackward0>))"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["q(text_ix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QS5HxSglhY7G","executionInfo":{"status":"ok","timestamp":1644472261030,"user_tz":-180,"elapsed":48,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}},"outputId":"21d0ac86-a7af-4768-fa5e-6120af6ed9fa"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[-0.0429, -0.2146, -0.2155,  ..., -0.3599,  0.3684,  0.0540],\n","          [-0.2025, -0.2482, -0.0260,  ...,  0.1194, -0.0978, -0.2387],\n","          [ 0.1182, -0.3729,  0.1004,  ...,  0.1361, -0.0398,  0.2033],\n","          ...,\n","          [ 0.2057, -0.2376, -0.4203,  ...,  0.1543, -0.0114,  0.0311],\n","          [-0.4793,  0.2932, -0.0450,  ...,  0.0253, -0.3619,  0.3519],\n","          [-0.1921, -0.0954, -0.2364,  ..., -0.0086,  0.0055, -0.5748]],\n"," \n","         [[-0.4772, -0.2793, -0.1564,  ...,  0.0118,  0.4160,  0.0244],\n","          [-0.5501,  0.2735,  0.1094,  ...,  0.3052, -0.0175, -0.2757],\n","          [ 0.0398, -0.1544,  0.0931,  ..., -0.2236,  0.3561, -0.4248],\n","          ...,\n","          [ 0.0285, -0.0603, -0.1965,  ...,  0.0502, -0.0306,  0.0064],\n","          [-0.3490,  0.1779, -0.0896,  ...,  0.0219, -0.2664,  0.0746],\n","          [-0.1611,  0.0215, -0.1424,  ...,  0.0317, -0.0079, -0.3733]]],\n","        grad_fn=<StackBackward0>),\n"," tensor([[[-4.7717e-01, -2.7927e-01, -1.5641e-01,  4.4366e-02,  2.6702e-01,\n","           -2.7007e-01, -2.2083e-01, -5.1539e-01, -2.4755e-01,  2.7467e-01,\n","           -1.6499e-01,  2.9307e-01, -2.6295e-01,  2.4687e-01, -2.1278e-01,\n","            1.7268e-01, -2.2571e-01,  1.1307e-01,  1.2191e-01,  8.4511e-02,\n","           -1.9142e-01, -4.3692e-01,  3.5444e-01, -1.9595e-01, -1.4612e-02,\n","           -2.9334e-02, -9.5081e-02, -8.3345e-02,  1.1235e-01,  7.7090e-02,\n","           -1.2106e-01,  5.2450e-01, -5.7562e-02,  5.8247e-02, -1.9478e-01,\n","            1.8511e-01, -1.2428e-01,  8.8116e-02,  8.7584e-02, -1.7609e-01,\n","           -4.6202e-01, -3.1683e-01, -7.4659e-02, -1.0269e-01,  5.5280e-01,\n","            1.3012e-02,  3.1112e-01,  4.5689e-01, -3.5276e-01,  4.4026e-02,\n","            5.8554e-02,  2.2052e-01,  4.0412e-01,  2.7442e-01,  2.9536e-01,\n","            2.7218e-01,  4.2515e-01, -3.9221e-01, -2.3176e-01, -3.3843e-02,\n","           -1.9176e-02,  1.1797e-02,  4.1596e-01,  2.4384e-02],\n","          [-5.5012e-01,  2.7349e-01,  1.0941e-01, -2.6270e-01, -2.8880e-01,\n","           -4.4712e-01,  4.6535e-01, -2.4188e-02, -1.3591e-01,  3.1452e-01,\n","           -4.2569e-01, -4.3197e-01, -1.4141e-02, -2.6121e-01,  1.9484e-01,\n","           -3.6727e-03, -1.6181e-01, -1.1473e-01,  3.3786e-01,  2.8046e-01,\n","            3.0337e-01,  5.3568e-01,  2.9324e-01,  2.4765e-01,  1.6056e-01,\n","           -2.7753e-01,  3.8411e-02, -2.1398e-01,  1.3217e-01,  2.3920e-01,\n","            1.7177e-01, -8.8928e-02,  4.7396e-01, -3.3735e-01, -6.0865e-02,\n","            2.0800e-01, -6.4688e-02,  3.4615e-03, -2.2845e-01,  3.9771e-01,\n","            5.1549e-01, -4.1260e-01, -3.1770e-02,  6.2583e-01, -3.0195e-01,\n","            1.6579e-01, -3.5266e-02, -4.3142e-02, -2.8336e-01, -3.7186e-02,\n","            8.5538e-02,  8.8142e-03, -1.6539e-01, -7.3800e-02,  1.9401e-01,\n","            1.4816e-01, -9.3111e-02,  5.9691e-02, -1.2609e-01,  2.2935e-01,\n","            1.6568e-01,  3.0525e-01, -1.7518e-02, -2.7570e-01],\n","          [ 3.9777e-02, -1.5439e-01,  9.3108e-02,  6.0900e-01, -1.1769e-01,\n","            3.0321e-01, -8.5689e-02, -5.1974e-01,  3.8942e-01,  2.3751e-02,\n","            1.5119e-01, -9.5917e-02,  2.8390e-01, -6.4290e-01,  2.8095e-02,\n","           -3.4912e-02,  2.5939e-01,  2.5502e-02,  4.7822e-01, -1.7868e-01,\n","           -4.1460e-02,  8.4170e-02,  2.0212e-01, -1.5224e-01,  7.0824e-02,\n","            8.9448e-02,  7.3724e-01,  1.9647e-01, -9.2280e-02, -3.5876e-01,\n","            1.7375e-01,  1.5939e-01,  3.1685e-01, -3.4692e-01, -3.3992e-01,\n","           -1.1440e-01, -5.7076e-01,  3.0662e-01, -1.9895e-01, -2.2028e-01,\n","            6.8114e-02, -3.6676e-02, -3.5163e-01, -2.9867e-01,  3.7134e-03,\n","           -3.0511e-01,  2.2882e-01, -2.9577e-01, -3.1077e-01, -1.9140e-01,\n","            1.8910e-01,  3.4944e-01, -2.3808e-01,  2.5429e-01,  7.9537e-02,\n","            1.1893e-02, -1.6477e-01, -8.8190e-02, -1.9079e-01, -7.1198e-02,\n","            6.0239e-01, -2.2356e-01,  3.5612e-01, -4.2475e-01],\n","          [-2.2426e-01, -9.7841e-02, -4.8018e-01, -4.6802e-01,  1.3435e-01,\n","            5.5645e-02, -5.4295e-01,  2.2993e-01,  2.4294e-01, -4.3251e-02,\n","           -5.4243e-02, -7.2534e-02, -2.7759e-01, -3.1805e-01,  2.7002e-01,\n","           -6.4524e-02,  4.0880e-02,  1.9018e-01, -5.5601e-02, -6.2679e-01,\n","           -1.4116e-01,  2.5921e-01, -7.2367e-03,  3.0762e-01, -1.1612e-01,\n","            6.0750e-01,  2.7577e-01,  2.0006e-01, -1.5669e-01, -8.5974e-02,\n","           -1.7728e-01,  3.3975e-01,  1.9390e-01, -1.6964e-02, -2.4294e-01,\n","           -3.4342e-01,  2.7206e-01, -1.0795e-01, -9.6110e-02, -1.6604e-01,\n","           -1.4570e-01, -7.8143e-02, -3.0552e-01,  1.8004e-01,  4.5583e-01,\n","            1.8020e-01,  5.8096e-02, -1.3470e-01, -1.7693e-01, -2.6934e-01,\n","           -3.4687e-01, -2.9997e-01,  4.4000e-02,  2.7420e-01, -2.4406e-01,\n","            2.7609e-01,  7.4946e-02, -1.1243e-01,  3.0933e-03,  6.9520e-01,\n","           -4.4761e-01,  2.9297e-02, -8.1663e-02, -4.7042e-01],\n","          [-2.1267e-01,  2.2589e-01,  1.1895e-01, -5.4075e-01,  9.7528e-02,\n","           -3.0821e-01,  1.1397e-01,  9.7726e-02,  8.3459e-02,  2.5564e-01,\n","           -4.3532e-01,  2.7668e-01, -7.8603e-02, -1.8754e-01, -1.8056e-02,\n","            2.4817e-01, -1.2748e-01,  3.5294e-01, -1.4287e-01,  3.9557e-01,\n","            3.4170e-01,  4.5458e-01, -1.1656e-01, -1.5654e-01,  3.1114e-02,\n","            6.1516e-02,  3.7382e-01, -3.2318e-01,  9.7296e-02,  1.4516e-01,\n","           -3.8697e-01,  1.4955e-01, -7.4155e-02, -4.0079e-01,  3.8716e-02,\n","            4.6149e-02, -4.6660e-01, -8.8293e-02, -5.9080e-02, -1.8603e-01,\n","           -1.8547e-01,  1.6378e-01, -3.9106e-01, -1.4925e-01, -2.9704e-02,\n","            1.2271e-01,  1.8644e-02,  1.1702e-01,  3.6512e-01, -3.0309e-01,\n","           -4.0604e-01, -2.9860e-01, -4.6870e-01, -7.0650e-02, -2.2180e-01,\n","            2.5126e-02,  1.4967e-01, -5.8055e-02, -2.5493e-01,  3.8703e-01,\n","           -7.3270e-02, -5.5195e-02,  3.8101e-01,  7.5756e-02],\n","          [ 3.4699e-02, -6.0294e-01,  9.1251e-02, -1.7119e-01, -6.2158e-02,\n","           -4.6086e-01, -3.2097e-01,  3.2808e-01,  5.2255e-02, -4.9474e-02,\n","            2.0153e-01, -2.2462e-01, -4.2285e-01, -1.9284e-01, -3.9467e-01,\n","           -1.9188e-01, -3.7042e-02,  5.1523e-01, -2.8272e-01, -6.0086e-01,\n","            3.4648e-02,  5.7095e-01,  4.8430e-01, -9.0167e-02,  4.6813e-01,\n","            1.7684e-01, -1.6085e-02,  2.1704e-01, -2.6747e-01, -5.3056e-01,\n","           -5.8647e-02,  1.3361e-01, -2.3530e-01, -1.6040e-01,  1.9666e-01,\n","           -1.2188e-01, -1.5035e-01, -3.0168e-01,  3.4573e-01, -7.5201e-02,\n","           -2.4087e-01, -1.7582e-01, -3.0123e-01, -1.7139e-01, -3.3413e-01,\n","            3.7911e-02,  5.6475e-01, -2.5392e-01,  2.4606e-02, -3.1771e-01,\n","            1.7767e-01,  1.7762e-01, -5.8418e-01,  3.9241e-02, -2.4970e-01,\n","            2.2871e-01, -3.9641e-01,  1.5791e-01,  1.5384e-01, -1.8538e-01,\n","            3.8827e-01, -2.5963e-02,  5.8971e-02, -1.7170e-01],\n","          [-4.8951e-01, -2.3391e-02,  3.3969e-01, -7.5510e-02,  1.8875e-01,\n","            2.7445e-01,  9.3501e-02, -4.3952e-01,  3.8155e-01,  1.9341e-01,\n","           -1.7718e-01,  3.6993e-01,  3.0768e-01, -2.5376e-01,  3.6918e-01,\n","           -3.7877e-01,  1.3794e-02,  2.9601e-01, -4.1677e-01,  2.7894e-01,\n","            7.6404e-02,  2.4232e-01, -2.5907e-01,  6.0102e-02, -1.6056e-01,\n","            3.3003e-01,  5.5812e-01,  7.1042e-02, -6.3344e-01,  4.3585e-01,\n","           -2.5978e-02, -2.6181e-01,  2.5834e-01, -2.2000e-01, -3.7584e-01,\n","            5.0658e-01,  9.9032e-02, -4.1073e-01, -1.7963e-01, -3.4391e-01,\n","            1.3709e-01, -6.3568e-04, -4.7604e-02,  2.2043e-01, -4.8976e-02,\n","           -4.5203e-01, -3.0877e-01,  3.9734e-01,  2.4316e-01, -3.9111e-01,\n","           -2.9690e-01,  2.6039e-02, -4.8080e-01,  4.0422e-01, -2.0779e-01,\n","            8.3593e-02, -1.5286e-02, -2.0563e-01, -1.7915e-01,  1.3822e-02,\n","            2.8452e-01, -2.7558e-01,  2.9129e-02,  1.0892e-01],\n","          [ 2.0691e-01, -5.0551e-01,  1.2576e-02,  2.6678e-01,  2.6868e-01,\n","           -9.2680e-02,  3.9037e-02, -2.8883e-01,  5.6798e-01, -9.7751e-02,\n","           -4.2472e-01,  1.1580e-01, -4.4572e-01,  6.7655e-01,  6.3379e-02,\n","            3.6133e-01, -1.1207e-01, -6.4738e-01,  8.5656e-02, -9.2974e-02,\n","           -4.0876e-01, -1.3247e-01,  7.0961e-02, -2.8905e-01,  4.5027e-02,\n","           -9.8339e-02, -1.5767e-01, -8.2578e-02, -7.2438e-02, -1.5150e-02,\n","            5.1020e-01, -1.1486e-01,  1.1616e-01, -3.2393e-01,  2.3954e-01,\n","            1.7121e-01, -7.2737e-01, -2.3851e-01, -3.0824e-01, -1.9333e-01,\n","           -6.5388e-01,  1.9286e-01, -5.3485e-01, -7.2541e-02,  2.3011e-01,\n","           -6.3225e-01, -1.3371e-01,  9.6941e-02, -3.8523e-01,  6.3255e-01,\n","           -2.2567e-01, -1.6969e-02, -5.1182e-01,  1.5875e-01,  1.3997e-01,\n","           -1.3075e-01, -2.4509e-01, -7.3922e-02,  3.7895e-02,  5.6458e-01,\n","            2.2471e-02,  1.6585e-01, -4.6567e-01, -4.7311e-01],\n","          [ 6.3680e-02,  2.7850e-01,  2.0405e-02,  2.3910e-01,  1.8997e-01,\n","            1.2682e-02, -3.6379e-01, -2.9489e-01,  7.0297e-02,  1.9374e-01,\n","            3.3268e-01,  1.0437e-01, -6.4714e-01,  3.6953e-03,  3.5204e-01,\n","            2.6353e-02,  6.2803e-02,  6.4434e-01,  4.7786e-01, -2.9390e-01,\n","            1.0423e-01,  1.3178e-01,  1.8379e-03,  4.3250e-01, -2.3833e-01,\n","           -2.0480e-01,  1.6962e-01, -3.4556e-02,  5.2710e-03,  6.0678e-02,\n","           -6.1543e-02, -3.0298e-01,  3.1777e-01, -5.4816e-01,  1.0977e-02,\n","           -7.2668e-02, -6.4904e-01,  6.3101e-02,  2.3766e-01, -3.5207e-01,\n","           -3.0940e-01, -4.0184e-01, -2.8497e-01,  2.4642e-01,  2.0723e-02,\n","           -7.4665e-03,  1.9773e-01, -7.4625e-02, -2.4217e-01, -9.6944e-02,\n","            3.2245e-01,  2.0971e-01, -5.8493e-01,  2.9347e-02, -3.8422e-01,\n","            2.4314e-01, -5.1002e-01,  2.7635e-01, -2.9562e-01, -1.0389e-01,\n","           -2.2230e-02,  3.3750e-01, -1.1079e-01, -6.1882e-01],\n","          [-2.8615e-01, -1.2301e-01, -3.5882e-01,  8.0749e-02, -2.3575e-01,\n","            2.4863e-01,  7.3516e-02,  6.8214e-02,  2.8225e-01,  7.0152e-02,\n","           -1.2205e-01, -2.8205e-02, -2.0319e-01, -9.5047e-02,  1.1008e-01,\n","           -2.5077e-01,  4.3876e-01,  1.7360e-01, -2.1894e-01,  1.0919e-01,\n","            3.2767e-02, -1.1144e-01, -2.4447e-01, -2.8215e-01,  2.0671e-01,\n","           -6.6923e-02,  4.6305e-01,  7.2201e-03,  7.0271e-02, -3.7631e-01,\n","           -4.6744e-02,  8.0428e-02, -5.8789e-02,  2.1501e-01, -5.4679e-02,\n","            5.9816e-02, -5.3930e-01,  1.1034e-01, -2.7405e-01,  4.3045e-01,\n","            1.4507e-01, -3.7731e-03,  1.5862e-01, -1.0858e-01, -1.8513e-01,\n","           -3.1126e-01,  2.8670e-01, -1.2379e-01, -3.7218e-02, -2.1262e-01,\n","           -9.0965e-02, -5.2198e-01, -5.7450e-01,  1.3597e-01, -4.9155e-01,\n","           -3.3584e-01, -3.2345e-01, -1.4990e-01, -3.8346e-01, -2.7209e-02,\n","            2.8246e-02, -2.7032e-01, -3.0021e-01, -6.9839e-01],\n","          [-2.5316e-01, -3.9101e-02, -1.6808e-01, -1.2639e-01,  5.3409e-02,\n","            1.9624e-01, -1.7238e-02,  1.5352e-02,  1.9238e-01,  7.1124e-02,\n","            7.9774e-02, -1.6421e-03,  1.2852e-01,  3.1139e-02, -1.4655e-01,\n","            1.3546e-01, -1.6293e-01, -1.1879e-01, -1.4935e-01, -8.7679e-02,\n","            1.0438e-01, -1.6747e-01,  4.2156e-02,  1.1234e-01, -1.3049e-02,\n","            8.2628e-02,  1.4711e-01, -1.2677e-01, -6.6369e-02, -1.0098e-02,\n","           -1.1813e-01, -1.1460e-01, -5.2107e-02,  1.4827e-01,  1.9568e-01,\n","            1.2850e-01, -2.0461e-02,  4.2932e-02,  1.6118e-01,  1.0054e-01,\n","           -3.7491e-03,  3.4928e-02, -1.5424e-01,  2.0054e-01,  1.8916e-01,\n","           -1.4489e-02, -5.4709e-02,  9.2228e-02, -1.5094e-01, -9.0972e-02,\n","           -8.2449e-02, -4.4596e-03,  7.9065e-02,  8.9893e-02,  3.5111e-02,\n","            2.2629e-02, -7.5728e-02, -2.4288e-01,  6.0303e-02,  1.4938e-01,\n","           -3.7642e-02,  7.8066e-02, -2.4002e-02, -3.7239e-02],\n","          [-2.9054e-01,  4.3339e-02, -6.6360e-02, -1.4494e-01, -2.5025e-02,\n","            1.9256e-01, -1.0469e-01, -2.8416e-01,  2.0571e-02, -1.9404e-02,\n","            1.2928e-01,  1.9696e-02,  2.8532e-02,  1.9386e-01, -3.3277e-02,\n","            1.3554e-01,  4.8755e-02,  1.6699e-01, -1.2965e-03, -9.7362e-02,\n","            1.7795e-01, -1.1171e-01, -6.9932e-02,  1.0316e-01,  4.0341e-02,\n","           -1.4001e-01,  2.0726e-01, -2.5013e-01, -5.4527e-02,  1.1155e-01,\n","           -3.9501e-02,  5.5099e-02, -2.2173e-01,  2.9617e-02,  5.4961e-04,\n","            1.3839e-01,  5.5150e-02, -7.2233e-02,  3.5178e-01, -1.8698e-01,\n","            5.4813e-02, -1.3950e-01,  1.7390e-01,  1.0465e-01, -4.2840e-03,\n","           -1.0652e-01,  3.0774e-04,  6.8204e-02, -5.3484e-02, -1.3602e-01,\n","           -9.4626e-03, -9.6574e-02,  2.0949e-01,  1.2974e-01, -4.4198e-02,\n","           -5.8606e-02,  7.6045e-02,  1.8129e-01, -9.0031e-02,  8.5975e-02,\n","            9.3622e-02,  7.7281e-02, -6.3691e-02,  4.9488e-02],\n","          [ 2.8476e-02, -6.0296e-02, -1.9654e-01, -6.0145e-02, -1.8535e-01,\n","            2.7032e-01,  1.5831e-01,  1.3048e-01,  1.0050e-01,  2.5173e-01,\n","           -2.1158e-02, -9.9406e-02,  9.1299e-02,  8.2673e-02, -2.7884e-01,\n","           -1.2785e-01, -3.7015e-02, -1.0365e-01, -1.7018e-01,  8.3789e-02,\n","            5.1027e-02, -1.1919e-01, -2.4014e-02, -6.9174e-02,  2.6428e-01,\n","            1.0153e-01,  1.7968e-01, -6.0091e-02,  3.7678e-04, -5.8087e-02,\n","            1.1190e-01, -2.3446e-01, -9.7331e-02,  1.3620e-01, -1.9844e-01,\n","            8.5829e-02, -7.0852e-02,  1.1372e-01,  9.1024e-02,  6.7058e-02,\n","            6.7301e-02, -6.1039e-03, -1.4858e-01, -5.3718e-02, -1.3023e-01,\n","           -1.7259e-01, -3.9603e-02, -9.8424e-03, -5.0727e-03, -2.6564e-01,\n","           -1.5587e-01,  6.3091e-03, -3.0911e-02,  1.0688e-01, -2.0265e-01,\n","           -1.8627e-01,  8.9083e-02, -1.2118e-01,  9.0601e-02, -1.3350e-01,\n","            1.8294e-01,  5.0210e-02, -3.0595e-02,  6.3516e-03],\n","          [-3.4900e-01,  1.7794e-01, -8.9574e-02, -2.0390e-01, -1.9441e-02,\n","            1.4891e-01,  1.0874e-01, -4.4969e-02,  1.2655e-01,  7.6632e-02,\n","            6.4265e-02, -9.3445e-02,  9.9508e-02, -3.8273e-02,  5.5825e-02,\n","           -8.9754e-02, -8.8209e-02, -1.9391e-01,  1.8467e-01,  7.5259e-02,\n","           -1.5376e-01,  2.3150e-01, -2.3276e-01, -3.1769e-02,  1.3528e-01,\n","           -4.0234e-02,  7.2761e-02, -8.6314e-02,  9.2598e-02,  1.9135e-02,\n","           -1.5288e-01,  2.5771e-01, -6.9845e-02, -6.1743e-02, -3.8777e-02,\n","            4.0813e-03,  1.3514e-01,  1.1558e-01,  1.5377e-01,  2.3245e-02,\n","           -8.6560e-02,  4.6646e-02,  2.0325e-01,  1.0228e-01, -4.5169e-02,\n","           -3.6487e-02,  1.2234e-01, -2.7619e-01, -3.2421e-02,  1.6069e-02,\n","           -2.8239e-01,  7.1498e-02,  2.2146e-02,  7.3036e-02,  1.0553e-01,\n","            1.0193e-01,  2.0701e-01, -2.6726e-01, -1.1947e-01, -5.0839e-02,\n","            1.2779e-01,  2.1917e-02, -2.6645e-01,  7.4587e-02],\n","          [-1.6110e-01,  2.1536e-02, -1.4245e-01,  6.5567e-02, -1.9112e-01,\n","            1.3246e-01,  1.6068e-04,  2.9735e-03,  1.0818e-01,  1.2582e-02,\n","           -6.4713e-02, -5.6329e-02, -6.1531e-02, -8.2589e-03,  1.6290e-01,\n","           -1.5030e-01,  2.7120e-01,  1.4351e-01, -1.0720e-01,  4.1478e-02,\n","           -8.4702e-03,  5.1482e-02, -2.1505e-02, -1.1097e-02,  6.4313e-02,\n","            1.8466e-02,  2.1842e-01,  5.5432e-02,  2.0321e-02, -1.1171e-01,\n","           -3.5219e-02, -2.8277e-02, -2.8192e-02,  4.8982e-02, -1.0134e-01,\n","            1.5122e-01, -1.9572e-01,  1.3239e-01, -1.1295e-01,  1.3462e-01,\n","            6.4609e-02, -2.4486e-02, -6.0380e-02,  2.9362e-02, -8.4236e-02,\n","           -1.9700e-01,  3.4036e-02, -9.1265e-02, -9.9538e-02, -1.1589e-01,\n","           -1.2350e-01, -4.8840e-02, -2.3507e-01,  4.3965e-02, -1.5452e-01,\n","           -9.6660e-02, -3.3959e-02, -7.0138e-02, -1.3496e-01, -9.9952e-02,\n","            3.5742e-03,  3.1710e-02, -7.9142e-03, -3.7328e-01]]],\n","        grad_fn=<StackBackward0>))"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"LLdm9gekzvDg","executionInfo":{"status":"ok","timestamp":1644472261031,"user_tz":-180,"elapsed":33,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["class AnswerVectorizer(nn.Module):\n","    def __init__(self, n_tokens=len(tokens), out_size=64, use_global_emb=True, hidden_size=128, batch_size = 32):\n","        \"\"\" \n","        A simple sequential encoder for questions.\n","        Use any combination of layers you want to encode a variable-length input \n","        to a fixed-size output vector\n","        \n","        If use_global_emb is True, use GLOBAL_EMB as your embedding layer\n","        \"\"\"\n","        super(self.__class__, self).__init__()\n","     \n","        self.n_tokens = n_tokens\n","        self.hidden_size = hidden_size\n","        self.out_size = out_size\n","        self.batch_size = batch_size\n","\n","        if use_global_emb:\n","            self.emb = GLOBAL_EMB\n","        else:\n","            self.emb = nn.Embedding(n_tokens, 64, padding_idx=PAD_ix)\n","            \n","        \n","        self.rnn = torch.nn.GRU(hidden_size, out_size)\n","\n","    def forward(self, text_ix):\n","        \"\"\"\n","        :param text_ix: int64 Variable of shape [batch_size, max_len]\n","        :returns: float32 Variable of shape [batch_size, out_size]\n","        \"\"\"\n","        emb = self.emb(text_ix)\n","        \n","        hidden = self.init_hidden(text_ix.shape)\n","        # print(text_ix.shape, emb.shape, hidden.shape)\n","        output, hidden = self.rnn(emb, hidden)\n","        return output, hidden\n","\n","    def init_hidden(self, hidden_size):\n","        #print(hidden_size)\n","        return torch.zeros(1, hidden_size[1], self.out_size) # self.batch_size"],"execution_count":30,"outputs":[]},{"cell_type":"code","source":["q = QuestionVectorizer(n_tokens=len(tokens), out_size=64, use_global_emb=True, batch_size=2, hidden_size=64)\n"],"metadata":{"id":"J1hQOWnIhw_b","executionInfo":{"status":"ok","timestamp":1644472261032,"user_tz":-180,"elapsed":33,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xm7FDKkzzvDh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472377294,"user_tz":-180,"elapsed":261,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}},"outputId":"8c572e8f-9bb4-4b72-ea80-bdd9820c3579"},"source":["for vectorizer in [QuestionVectorizer(out_size=128), AnswerVectorizer(out_size=128)]:\n","    print(\"Testing %s ...\" % vectorizer.__class__.__name__)\n","    dummy_x = Variable(torch.LongTensor(test))\n","    # dummy_v = vectorizer(dummy_x)\n","    # print(QuestionVectorizer(dummy_x))\n","    assert 1 # isinstance(dummy_v, Variable)\n","    assert 1 # tuple(dummy_v.shape[0], dummy_v.shape[2]) == (dummy_x.shape[0], 128)\n","\n","    del vectorizer\n","    print(\"Seems fine\")"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing QuestionVectorizer ...\n","Seems fine\n","Testing AnswerVectorizer ...\n","Seems fine\n"]}]},{"cell_type":"code","metadata":{"id":"CKfT16nQzvDj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644472380209,"user_tz":-180,"elapsed":13,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}},"outputId":"f8f836cb-221a-459f-f613-ede77fc4422e"},"source":["from itertools import chain\n","\n","question_vectorizer = QuestionVectorizer()\n","answer_vectorizer = AnswerVectorizer()\n","\n","opt = torch.optim.Adam(chain(question_vectorizer.parameters(),\n","                             answer_vectorizer.parameters()))"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py:74: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n","  super(Adam, self).__init__(params, defaults)\n"]}]},{"cell_type":"markdown","source":["### Code"],"metadata":{"id":"9kpxF9heOwsS"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","\n","\n","def slice_arrays(arrays, start=None, stop=None):\n","    if arrays is None:\n","        return [None]\n","\n","    if isinstance(arrays, np.ndarray):\n","        arrays = [arrays]\n","\n","    if isinstance(start, list) and stop is not None:\n","        raise ValueError('The stop argument has to be None if the value of start '\n","                         'is a list.')\n","    elif isinstance(arrays, list):\n","        if hasattr(start, '__len__'):\n","            # hdf5 datasets only support list objects as indices\n","            if hasattr(start, 'shape'):\n","                start = start.tolist()\n","            return [None if x is None else x[start] for x in arrays]\n","        else:\n","            if len(arrays) == 1:\n","                return arrays[0][start:stop]\n","            return [None if x is None else x[start:stop] for x in arrays]\n","    else:\n","        if hasattr(start, '__len__'):\n","            if hasattr(start, 'shape'):\n","                start = start.tolist()\n","            return arrays[start]\n","        elif hasattr(start, '__getitem__'):\n","            return arrays[start:stop]\n","        else:\n","            return [None]\n","\n","\n","def Cosine_Similarity(query, candidate, gamma=1, dim=-1):\n","    query_norm = torch.norm(query, dim=dim)\n","    candidate_norm = torch.norm(candidate, dim=dim)\n","    cosine_score = torch.sum(torch.multiply(query, candidate), dim=-1)\n","    cosine_score = torch.div(cosine_score, query_norm*candidate_norm+1e-8)\n","    cosine_score = torch.clamp(cosine_score, -1, 1.0)*gamma\n","    return cosine_score"],"metadata":{"id":"TrgH7_msliHe","executionInfo":{"status":"ok","timestamp":1644472382562,"user_tz":-180,"elapsed":10,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["class DNN(nn.Module):\n","    def __init__(self, inputs_dim, hidden_units, activation='relu', l2_reg=0, dropout_rate=0, use_bn=False,\n","                 init_std=0.0001, dice_dim=3, seed=1024, device='cpu'):\n","        super(DNN, self).__init__()\n","        self.dropout_rate = dropout_rate\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.seed = seed\n","        self.l2_reg = l2_reg\n","        self.use_bn = use_bn\n","        if len(hidden_units) == 0:\n","            raise ValueError(\"hidden_units is empty!!\")\n","        if inputs_dim > 0:\n","            hidden_units = [inputs_dim] + list(hidden_units)\n","        else:\n","            hidden_units = list(hidden_units)\n","\n","        self.linears = nn.ModuleList(\n","            [nn.Linear(hidden_units[i], hidden_units[i+1]) for i in range(len(hidden_units) - 1)])\n","\n","        if self.use_bn:\n","            self.bn = nn.ModuleList(\n","                [nn.BatchNorm1d(hidden_units[i+1]) for i in range(len(hidden_units) - 1)])\n","\n","        self.activation_layers = nn.ModuleList(\n","            [activation_layer(activation, hidden_units[i+1], dice_dim) for i in range(len(hidden_units) - 1)])\n","\n","        for name, tensor in self.linears.named_parameters():\n","            if 'weight' in name:\n","                nn.init.normal_(tensor, mean=0, std=init_std)\n","\n","        self.to(device)\n","\n","    def forward(self, inputs):\n","        deep_input = inputs\n","        for i in range(len(self.linears)):\n","            fc = self.linears[i](deep_input)\n","\n","            if self.use_bn:\n","                fc = self.bn[i](fc)\n","\n","            fc = self.activation_layers[i](fc)\n","\n","            fc = self.dropout(fc)\n","            deep_input = fc\n","        return deep_input"],"metadata":{"id":"0zdR2lPrLHYE","executionInfo":{"status":"ok","timestamp":1644472389894,"user_tz":-180,"elapsed":264,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","\n","class Identity(nn.Module):\n","    def __init__(self, **kwargs):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, X):\n","        return X\n","\n","\n","def activation_layer(act_name, hidden_size=None, dice_dim=2):\n","    if isinstance(act_name, str):\n","        if act_name.lower() == 'sigmoid':\n","            act_layer = nn.Sigmoid()\n","        elif act_name.lower() == 'linear':\n","            act_layer = Identity()\n","        elif act_name.lower() == 'relu':\n","            act_layer = nn.ReLU(inplace=True)\n","        elif act_name.lower() == 'dice':\n","            assert dice_dim\n","            # act_layer = Dice(hidden_size, dice_dim)\n","        elif act_name.lower() == 'prelu':\n","            act_layer = nn.PReLU()\n","        elif issubclass(act_name, nn.Module):\n","            act_layer = act_name()\n","        else:\n","            raise NotImplementedError\n","\n","        return act_layer"],"metadata":{"id":"EG8CAIFqM09-","executionInfo":{"status":"ok","timestamp":1644472523348,"user_tz":-180,"elapsed":5,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","\n","class PredictionLayer(nn.Module):\n","    def __init__(self, task='binary', use_bias=True, **kwargs):\n","        if task not in [\"binary\", \"multiclass\", \"regression\"]:\n","            raise ValueError(\"task must be binary,multiclass or regression\")\n","\n","        super(PredictionLayer, self).__init__()\n","        self.use_bias = use_bias\n","        self.task = task\n","        if self.use_bias:\n","            self.bias = nn.Parameter(torch.zeros((1,)))\n","\n","    def forward(self, X):\n","        output = X\n","        if self.use_bias:\n","            output += self.bias\n","        if self.task == \"binary\":\n","            output = torch.sigmoid(X)\n","        return output\n","\n","\n","class DNN(nn.Module):\n","    def __init__(self, inputs_dim, hidden_units, activation='relu', l2_reg=0, dropout_rate=0, use_bn=False,\n","                 init_std=0.0001, dice_dim=3, seed=1024, device='cpu'):\n","        super(DNN, self).__init__()\n","        self.dropout_rate = dropout_rate\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.seed = seed\n","        self.l2_reg = l2_reg\n","        self.use_bn = use_bn\n","        if len(hidden_units) == 0:\n","            raise ValueError(\"hidden_units is empty!!\")\n","        if inputs_dim > 0:\n","            hidden_units = [inputs_dim] + list(hidden_units)\n","        else:\n","            hidden_units = list(hidden_units)\n","\n","        self.linears = nn.ModuleList(\n","            [nn.Linear(hidden_units[i], hidden_units[i+1]) for i in range(len(hidden_units) - 1)])\n","\n","        if self.use_bn:\n","            self.bn = nn.ModuleList(\n","                [nn.BatchNorm1d(hidden_units[i+1]) for i in range(len(hidden_units) - 1)])\n","\n","        self.activation_layers = nn.ModuleList(\n","            [activation_layer(activation, hidden_units[i+1], dice_dim) for i in range(len(hidden_units) - 1)])\n","\n","        for name, tensor in self.linears.named_parameters():\n","            if 'weight' in name:\n","                nn.init.normal_(tensor, mean=0, std=init_std)\n","\n","        self.to(device)\n","\n","    def forward(self, inputs):\n","        deep_input = inputs\n","        for i in range(len(self.linears)):\n","            fc = self.linears[i](deep_input)\n","\n","            if self.use_bn:\n","                fc = self.bn[i](fc)\n","\n","            fc = self.activation_layers[i](fc)\n","\n","            fc = self.dropout(fc)\n","            deep_input = fc\n","        return deep_input\n","\n","\n","class LocalActivationUnit(nn.Module):\n","    def __init__(self, hidden_units=(64, 32), embedding_dim=4, activation='sigmoid', dropout_rate=0,\n","                 dice_dim=3, l2_reg=0, use_bn=False):\n","        super(LocalActivationUnit, self).__init__()\n","\n","        self.dnn = DNN(inputs_dim=4 * embedding_dim,\n","                       hidden_units=hidden_units,\n","                       activation=activation,\n","                       l2_reg=l2_reg,\n","                       dropout_rate=dropout_rate,\n","                       dice_dim=dice_dim,\n","                       use_bn=use_bn)\n","\n","        self.dense = nn.Linear(hidden_units[-1], 1)\n","\n","    def forward(self, query, user_behavier):\n","        # query ad            : size -> batch_size * 1 * embedding_size\n","        # user behavior       : size -> batch_size * time_seq_len * embedding_size\n","        user_behavier_len = user_behavier.size(1)\n","\n","        queries = query.expand(-1, user_behavier_len, -1)\n","\n","        attention_input = torch.cat([queries, user_behavier, queries - user_behavier, queries * user_behavier],\n","                                    dim=-1)    # [B, T, 4*E]\n","        attention_out = self.dnn(attention_input)\n","\n","        attention_score = self.dense(attention_out)    # [B, T, 1]\n","\n","        return attention_score\n"],"metadata":{"id":"z2hSnwf0MwtC","executionInfo":{"status":"ok","timestamp":1644472528979,"user_tz":-180,"elapsed":277,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","\n","class SequencePoolingLayer(nn.Module):\n","    def __init__(self, mode='mean', support_masking=False, device='cpu'):\n","        super(SequencePoolingLayer, self).__init__()\n","        if mode not in ['sum', 'mean', 'max']:\n","            raise ValueError('parameter mode should in [sum, mean, max]')\n","        self.supports_masking = support_masking\n","        self.mode = mode\n","        self.device = device\n","        self.eps = torch.FloatTensor([1e-8]).to(device)\n","        self.to(device)\n","\n","    def _sequence_mask(self, lengths, maxlen=None, dtype=torch.bool):\n","        # Returns a mask tensor representing the first N positions of each cell.\n","        if maxlen is None:\n","            maxlen = lengths.max()\n","        row_vector = torch.arange(0, maxlen, 1).to(lengths.device)\n","        matrix = torch.unsqueeze(lengths, dim=-1)\n","        mask = row_vector < matrix\n","\n","        mask.type(dtype)\n","        return mask\n","\n","    def forward(self, seq_value_len_list):\n","        if self.supports_masking:\n","            uiseq_embed_list, mask = seq_value_len_list    # [B, T, E], [B, 1]\n","            mask = mask.float()\n","            user_behavior_length = torch.sum(mask, 1, keepdim=True)\n","            mask = mask.unsqueeze(2)\n","        else:\n","            uiseq_embed_list, user_behavior_length = seq_value_len_list    # [B, T, E], [B, 1]\n","            mask = self._sequence_mask(user_behavior_length, maxlen=uiseq_embed_list.shape[1], dtype=torch.float32)\n","            mask = torch.transpose(mask, 1, 2)\n","\n","        embedding_size = uiseq_embed_list.shape[-1]\n","\n","        mask = torch.repeat_interleave(mask, embedding_size, dim=2)  # [B, maxlen, E]\n","\n","        if self.mode == 'max':\n","            hist = uiseq_embed_list - (1 - mask) * 1e9\n","            hist = torch.max(hist, dim=1, keepdim=True)[0]\n","            return hist\n","        hist = uiseq_embed_list * mask.float()\n","        hist = torch.sum(hist, dim=1, keepdim=False)\n","\n","        if self.mode == 'mean':\n","            self.eps = self.eps.to(user_behavior_length.device)\n","            hist = torch.div(hist, user_behavior_length.type(torch.float32) + self.eps)\n","\n","        hist = torch.unsqueeze(hist, dim=1)\n","        return hist\n","\n","\n","class AttentionSequencePoolingLayer(nn.Module):\n","    def __init__(self, att_hidden_units=(80, 40), att_activation='sigmoid', weight_normalization=False,\n","                 return_score=False, supports_masking=False, embedding_dim=4, **kwargs):\n","        super(AttentionSequencePoolingLayer, self).__init__()\n","        self.return_score = return_score\n","        self.weight_normalization = weight_normalization\n","        self.supports_masking = supports_masking\n","        self.local_att = LocalActivationUnit(hidden_units=att_hidden_units, embedding_dim=embedding_dim,\n","                                             activation=att_activation, dropout_rate=0, use_bn=False)\n","\n","    def forward(self, query, keys, keys_length, mask=None):\n","        batch_size, max_length, _ = keys.size()\n","\n","        # Mask\n","        if self.supports_masking:\n","            if mask is None:\n","                raise ValueError(\"When supports_masking=True,input must support masking\")\n","            keys_masks = mask.unsqueeze(1)\n","        else:\n","            keys_masks = torch.arange(max_length, device=keys_length.device,\n","                                      dtype=keys_length.dtype).repeat(batch_size, 1)  # [B, T]\n","            keys_masks = keys_masks < keys_length.view(-1, 1)  # 0, 1 mask\n","            keys_masks = keys_masks.unsqueeze(1)  # [B, 1, T]\n","\n","        attention_score = self.local_att(query, keys)  # [B, T, 1]\n","\n","        outputs = torch.transpose(attention_score, 1, 2)  # [B, 1, T]\n","\n","        if self.weight_normalization:\n","            paddings = torch.ones_like(outputs) * (-2 ** 32 + 1)\n","        else:\n","            paddings = torch.zeros_like(outputs)\n","\n","        outputs = torch.where(keys_masks, outputs, paddings)  # [B, 1, T]\n","\n","        if self.weight_normalization:\n","            outputs = F.softmax(outputs, dim=-1)  # [B, 1, T]\n","\n","        if not self.return_score:\n","            # Weighted sum\n","            outputs = torch.matmul(outputs, keys)  # [B, 1, E]\n","\n","        return outputs"],"metadata":{"id":"bNtazkcCMqsb","executionInfo":{"status":"ok","timestamp":1644472534942,"user_tz":-180,"elapsed":265,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from collections import OrderedDict, namedtuple\n","from collections import OrderedDict, namedtuple, defaultdict\n","from itertools import chain\n","\n","DEFAULT_GROUP_NAME = \"default_group\"\n","\n","\n","class SparseFeat(namedtuple('SparseFeat', ['name', 'vocabulary_size', 'embedding_dim', 'use_hash', 'dtype',\n","                                           'embedding_name', 'group_name'])):\n","    def __new__(cls, name, vocabulary_size, embedding_dim=4, use_hash=False, dtype='int32', embedding_name=None,\n","                group_name=DEFAULT_GROUP_NAME):\n","        if embedding_name is None:\n","            embedding_name = name\n","        if embedding_dim == 'auto':\n","            embedding_dim = 6 * int(pow(vocabulary_size, 0.25))\n","        if use_hash:\n","            print(\"Notice! Feature Hashing on the fly currently!\")\n","        return super(SparseFeat, cls).__new__(cls, name, vocabulary_size, embedding_dim, use_hash, dtype,\n","                                              embedding_name, group_name)\n","\n","    def __hash__(self):\n","        return self.name.__hash__()\n","\n","\n","class VarLenSparseFeat(namedtuple('VarLenSparseFeat', ['sparsefeat', 'maxlen', 'combiner', 'length_name'])):\n","    def __new__(cls, sparsefeat, maxlen, combiner='mean', length_name=None):\n","        return super(VarLenSparseFeat, cls).__new__(cls, sparsefeat, maxlen, combiner, length_name)\n","\n","    @property\n","    def name(self):\n","        return self.sparsefeat.name\n","\n","    @property\n","    def vocabulary_size(self):\n","        return self.sparsefeat.vocabulary_size\n","\n","    @property\n","    def embedding_dim(self):\n","        return self.sparsefeat.embedding_dim\n","\n","    @property\n","    def dtype(self):\n","        return self.sparsefeat.dtype\n","\n","    @property\n","    def embedding_name(self):\n","        return self.sparsefeat.embedding_name\n","\n","    @property\n","    def group_name(self):\n","        return self.sparsefeat.group_name\n","\n","    def __hash__(self):\n","        return self.name.__hash__()\n","\n","\n","class DenseFeat(namedtuple('DenseFeat', ['name', 'dimension', 'dtype'])):\n","    def __new__(cls, name, dimension=1, dtype=\"float32\"):\n","        return super(DenseFeat, cls).__new__(cls, name, dimension, dtype)\n","\n","    def __hash__(self):\n","        return self.name.__hash__()\n","\n","\n","def create_embedding_matrix(feature_columns, init_std=0.0001, linear=False, sparse=False, device='cpu'):\n","    sparse_feature_columns = list(\n","        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n","\n","    varlen_sparse_feature_columns = list(\n","        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if len(feature_columns) else []\n","\n","    embedding_dict = nn.ModuleDict({feat.embedding_name: nn.Embedding(feat.vocabulary_size,\n","                                                                      feat.embedding_dim if not linear else 1)\n","                                    for feat in sparse_feature_columns + varlen_sparse_feature_columns})\n","\n","    for tensor in embedding_dict.values():\n","        nn.init.normal_(tensor.weight, mean=0, std=init_std)\n","\n","    return embedding_dict.to(device)\n","\n","\n","def get_varlen_pooling_list(embedding_dict, features, feature_index, varlen_sparse_feature_columns, device):\n","    varlen_sparse_embedding_list = []\n","\n","    for feat in varlen_sparse_feature_columns:\n","        seq_emb = embedding_dict[feat.embedding_name](\n","                        features[:, feature_index[feat.name][0]:feature_index[feat.name][1]].long())\n","        if feat.length_name is None:\n","            seq_mask = features[:, feature_index[feat.name][0]:feature_index[feat.name][1]].long() != 0\n","\n","            emb = SequencePoolingLayer(mode=feat.combiner, support_masking=True, device=device)([seq_emb, seq_mask])\n","\n","        else:\n","            seq_length = features[:, feature_index[feat.length_name][0]:feature_index[feat.length_name][1]].long()\n","\n","            emb = SequencePoolingLayer(mode=feat.combiner, support_masking=False, device=device)([seq_emb, seq_length])\n","\n","        varlen_sparse_embedding_list.append(emb)\n","\n","    return varlen_sparse_embedding_list\n","\n","\n","def build_input_features(feature_columns):\n","    features = OrderedDict()\n","\n","    start = 0\n","    for feat in feature_columns:\n","        feat_name = feat.name\n","        if feat_name in features:\n","            continue\n","        if isinstance(feat, SparseFeat):\n","            features[feat_name] = (start, start + 1)\n","            start += 1\n","        elif isinstance(feat, DenseFeat):\n","            features[feat_name] = (start, start + feat.dimension)\n","            start += feat.dimension\n","        elif isinstance(feat, VarLenSparseFeat):\n","            features[feat_name] = (start, start + feat.maxlen)\n","            start += feat.maxlen\n","            if feat.length_name is not None and feat.length_name not in features:\n","                features[feat.length_name] = (start, start+1)\n","                start += 1\n","        else:\n","            raise TypeError(\"Invalid feature column type,got\", type(feat))\n","    return features\n","\n","\n","def get_feature_names(feature_columns):\n","    features = build_input_features(feature_columns)\n","    return list(features.keys())\n","\n","\n","def concat_fun(inputs, axis=-1):\n","    if len(inputs) == 1:\n","        return inputs[0]\n","    else:\n","        return torch.cat(inputs, dim=axis)\n","\n","\n","def combined_dnn_input(sparse_embedding_list, dense_value_list):\n","    if len(sparse_embedding_list) > 0 and len(dense_value_list) > 0:\n","        sparse_dnn_input = torch.flatten(\n","            torch.cat(sparse_embedding_list, dim=-1), start_dim=1)\n","        dense_dnn_input = torch.flatten(\n","            torch.cat(dense_value_list, dim=-1), start_dim=1)\n","        return concat_fun([sparse_dnn_input, dense_dnn_input])\n","    elif len(sparse_embedding_list) > 0:\n","        return torch.flatten(torch.cat(sparse_embedding_list, dim=-1), start_dim=1)\n","    elif len(dense_value_list) > 0:\n","        return torch.flatten(torch.cat(dense_value_list, dim=-1), start_dim=1)\n","    else:\n","        raise NotImplementedError\n","\n","\n","def input_from_feature_columns(X, feature_index, feature_columns, embedding_dict, support_dense=True, device='cpu'):\n","    sparse_feature_columns = list(\n","        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n","    dense_feature_columns = list(\n","        filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n","\n","    varlen_sparse_feature_columns = list(\n","        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n","\n","    if not support_dense and len(dense_feature_columns) > 0:\n","        raise ValueError(\n","            \"DenseFeat is not supported in dnn_feature_columns\")\n","\n","    sparse_embedding_list = [embedding_dict[feat.embedding_name](\n","        X[:, feature_index[feat.name][0]:feature_index[feat.name][1]].long()) for feat in sparse_feature_columns]\n","\n","    varlen_sparse_embedding_list = get_varlen_pooling_list(embedding_dict, X, feature_index,\n","                                                           varlen_sparse_feature_columns, device)\n","\n","    dense_value_list = [X[:, feature_index[feat.name][0]:feature_index[feat.name][1]] for feat in dense_feature_columns]\n","\n","    return sparse_embedding_list + varlen_sparse_embedding_list, dense_value_list\n","\n","\n","def compute_input_dim(feature_columns, include_sparse=True, include_dense=True, feature_group=False):\n","    sparse_feature_columns = list(\n","        filter(lambda x: isinstance(x, (SparseFeat, VarLenSparseFeat)), feature_columns)) if len(\n","        feature_columns) else []\n","    dense_feature_columns = list(\n","        filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n","\n","    dense_input_dim = sum(map(lambda x: x.dimension, dense_feature_columns))\n","    if feature_group:\n","        sparse_input_dim = len(sparse_feature_columns)\n","    else:\n","        sparse_input_dim = sum(feat.embedding_dim for feat in sparse_feature_columns)\n","    input_dim = 0\n","    if include_sparse:\n","        input_dim += sparse_input_dim\n","    if include_dense:\n","        input_dim += dense_input_dim\n","    return input_dim\n","\n","\n","def embedding_lookup(X, sparse_embedding_dict, sparse_input_dict, sparse_feature_columns,\n","                     return_feat_list=(), mask_feat_list=(), to_list=False):\n","    group_embedding_dict = defaultdict(list)\n","    for fc in sparse_feature_columns:\n","        feature_name = fc.name\n","        embedding_name = fc.embedding_name\n","        if len(return_feat_list) == 0 or feature_name in return_feat_list:\n","            lookup_idx = np.array(sparse_input_dict[feature_name])\n","            input_tensor = X[:, lookup_idx[0]:lookup_idx[1]].long()\n","            emb = sparse_embedding_dict[embedding_name](input_tensor)\n","            group_embedding_dict[fc.group_name].append(emb)\n","    if to_list:\n","        return list(chain.from_iterable(group_embedding_dict.values()))\n","    return group_embedding_dict\n","\n","\n","def varlen_embedding_lookup(X, embedding_dict, sequence_input_dict, varlen_sparse_feature_columns):\n","    varlen_embedding_vec_dict = {}\n","    for fc in varlen_sparse_feature_columns:\n","        feature_name = fc.name\n","        embedding_name = fc.embedding_name\n","        if fc.use_hash:\n","            # lookup_idx = Hash(fc.vocabulary_size, mask_zero=True)(sequence_input_dict[feature_name])\n","            # TODO: add hash function\n","            lookup_idx = sequence_input_dict[feature_name]\n","        else:\n","            lookup_idx = sequence_input_dict[feature_name]\n","        varlen_embedding_vec_dict[feature_name] = embedding_dict[embedding_name](\n","            X[:, lookup_idx[0]:lookup_idx[1]].long())  # (lookup_idx)\n","\n","    return varlen_embedding_vec_dict\n","\n","\n","def maxlen_lookup(X, sparse_input_dict, maxlen_column):\n","    if maxlen_column is None or len(maxlen_column)==0:\n","        raise ValueError('please add max length column for VarLenSparseFeat of DIN/DIEN input')\n","    lookup_idx = np.array(sparse_input_dict[maxlen_column[0]])\n","    return X[:, lookup_idx[0]:lookup_idx[1]].long()\n","\n","# if __name__ == '__main__':\n","#     user_id = SparseFeat('user_id', 1000, embedding_dim=4)\n","#     score_avg = DenseFeat('score_avg', dimension=1)\n","#     user_hist = VarLenSparseFeat(SparseFeat('user_hist', 1000, embedding_dim=4), 666)"],"metadata":{"id":"7IJD21XKLc43","executionInfo":{"status":"ok","timestamp":1644472542965,"user_tz":-180,"elapsed":970,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["from __future__ import print_function\n","\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data as Data\n","from sklearn.metrics import *\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","\n","\n","class BaseTower(nn.Module):\n","    def __init__(self, user_dnn_feature_columns, item_dnn_feature_columns, l2_reg_embedding=1e-5,\n","                 init_std=0.0001, seed=1024, task='binary', device='cpu', gpus=None):\n","        super(BaseTower, self).__init__()\n","        torch.manual_seed(seed)\n","\n","        self.reg_loss = torch.zeros((1,), device=device)\n","        self.aux_loss = torch.zeros((1,), device=device)\n","        self.device = device\n","        self.gpus = gpus\n","        if self.gpus and str(self.gpus[0]) not in self.device:\n","            raise ValueError(\"`gpus[0]` should be the same gpu with `device`\")\n","\n","        self.feature_index = build_input_features(user_dnn_feature_columns + item_dnn_feature_columns)\n","\n","        self.user_dnn_feature_columns = user_dnn_feature_columns\n","        self.user_embedding_dict = create_embedding_matrix(self.user_dnn_feature_columns, init_std,\n","                                                           sparse=False, device=device)\n","\n","        self.item_dnn_feature_columns = item_dnn_feature_columns\n","        self.item_embedding_dict = create_embedding_matrix(self.item_dnn_feature_columns, init_std,\n","                                                           sparse=False, device=device)\n","\n","        self.regularization_weight = []\n","        self.add_regularization_weight(self.user_embedding_dict.parameters(), l2=l2_reg_embedding)\n","        self.add_regularization_weight(self.item_embedding_dict.parameters(), l2=l2_reg_embedding)\n","\n","        self.out = PredictionLayer(task,)\n","        self.to(device)\n","\n","        # parameters of callbacks\n","        self._is_graph_network = True  # used for ModelCheckpoint\n","        self.stop_training = False  # used for EarlyStopping\n","\n","    def fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, initial_epoch=0, validation_split=0.,\n","            validation_data=None, shuffle=True, callbacks=None):\n","        if isinstance(x, dict):\n","            x = [x[feature] for feature in self.feature_index]\n","\n","        do_validation = False\n","        if validation_data:\n","            do_validation = True\n","            if len(validation_data) == 2:\n","                val_x, val_y = validation_data\n","                val_sample_weight = None\n","            elif len(validation_data) == 3:\n","                val_x, val_y, val_sample_weight = validation_data\n","            else:\n","                raise ValueError(\n","                    'When passing a `validation_data` argument, '\n","                    'it must contain either 2 items (x_val, y_val), '\n","                    'or 3 items (x_val, y_val, val_sample_weights), '\n","                    'or alternatively it could be a dataset or a '\n","                    'dataset or a dataset iterator. '\n","                    'However we received `validation_data=%s`' % validation_data)\n","\n","            if isinstance(val_x, dict):\n","                val_x = [val_x[feature] for feature in self.feature_index]\n","\n","        elif validation_split and 0 < validation_split < 1.:\n","            do_validation = True\n","            if hasattr(x[0], 'shape'):\n","                split_at = int(x[0].shape[0] * (1. - validation_split))\n","            else:\n","                split_at = int(len(x[0]) * (1. - validation_split))\n","\n","            x, val_x = (slice_arrays(x, 0, split_at),\n","                        slice_arrays(x, split_at))\n","            y, val_y = (slice_arrays(y, 0, split_at),\n","                        slice_arrays(y, split_at))\n","\n","        else:\n","            val_x = []\n","            val_y = []\n","\n","        for i in range(len(x)):\n","            if len(x[i].shape) == 1:\n","                x[i] = np.expand_dims(x[i], axis=1)\n","\n","        train_tensor_data = Data.TensorDataset(torch.from_numpy(\n","            np.concatenate(x, axis=-1)), torch.from_numpy(y))\n","        if batch_size is None:\n","            batch_size = 256\n","\n","        model = self.train()\n","        loss_func = self.loss_func\n","        optim = self.optim\n","\n","        if self.gpus:\n","            print('parallel running on these gpus:', self.gpus)\n","            model = torch.nn.DataParallel(model, device_ids=self.gpus)\n","            batch_size *= len(self.gpus)  # input `batch_size` is batch_size per gpu\n","        else:\n","            print(self.device)\n","\n","        train_loader = DataLoader(dataset=train_tensor_data, shuffle=shuffle, batch_size=batch_size)\n","\n","        sample_num = len(train_tensor_data)\n","        steps_per_epoch = (sample_num - 1) // batch_size + 1\n","\n","        # train\n","        print(\"Train on {0} samples, validate on {1} samples, {2} steps per epoch\".format(\n","            len(train_tensor_data), len(val_y), steps_per_epoch))\n","        for epoch in range(initial_epoch, epochs):\n","            epoch_logs = {}\n","            start_time = time.time()\n","            loss_epoch = 0\n","            total_loss_epoch = 0\n","            train_result = {}\n","\n","            with tqdm(enumerate(train_loader), disable=verbose != 1) as t:\n","                for _, (x_train, y_train) in t:\n","                    x = x_train.to(self.device).float()\n","                    y = y_train.to(self.device).float()\n","\n","                    y_pred = model(x).squeeze()\n","\n","                    optim.zero_grad()\n","                    loss = loss_func(y_pred, y.squeeze(), reduction='sum')\n","                    reg_loss = self.get_regularization_loss()\n","\n","                    total_loss = loss + reg_loss + self.aux_loss\n","\n","                    loss_epoch += loss.item()\n","                    total_loss_epoch += total_loss.item()\n","                    total_loss.backward()\n","                    optim.step()\n","\n","                    if verbose > 0:\n","                        for name, metric_fun in self.metrics.items():\n","                            if name not in train_result:\n","                                train_result[name] = []\n","                            train_result[name].append(metric_fun(\n","                                y.cpu().data.numpy(), y_pred.cpu().data.numpy().astype('float64')\n","                            ))\n","\n","            # add epoch_logs\n","            epoch_logs[\"loss\"] = total_loss_epoch / sample_num\n","            for name, result in train_result.items():\n","                epoch_logs[name] = np.sum(result) / steps_per_epoch\n","\n","            if do_validation:\n","                eval_result = self.evaluate(val_x, val_y, batch_size)\n","                for name, result in eval_result.items():\n","                    epoch_logs[\"val_\" + name] = result\n","\n","            if verbose > 0:\n","                epoch_time = int(time.time() - start_time)\n","                print('Epoch {0}/{1}'.format(epoch + 1, epochs))\n","\n","                eval_str = \"{0}s - loss: {1: .4f}\".format(epoch_time, epoch_logs[\"loss\"])\n","\n","                for name in self.metrics:\n","                    eval_str += \" - \" + name + \": {0: .4f} \".format(epoch_logs[name]) + \" - \" + \\\n","                                \"val_\" + name + \": {0: .4f}\".format(epoch_logs[\"val_\" + name])\n","                print(eval_str)\n","            if self.stop_training:\n","                break\n","\n","    def evaluate(self, x, y, batch_size=256):\n","        pred_ans = self.predict(x, batch_size)\n","        eval_result = {}\n","        for name, metric_fun in self.metrics.items():\n","            eval_result[name] = metric_fun(y, pred_ans)\n","        return eval_result\n","\n","    def predict(self, x, batch_size=256):\n","        model = self.eval()\n","        if isinstance(x, dict):\n","            x = [x[feature] for feature in self.feature_index]\n","        for i in range(len(x)):\n","            if len(x[i].shape) == 1:\n","                x[i] = np.expand_dims(x[i], axis=1)\n","\n","        tensor_data = Data.TensorDataset(\n","            torch.from_numpy(np.concatenate(x, axis=-1))\n","        )\n","        test_loader = DataLoader(\n","            dataset=tensor_data, shuffle=False, batch_size=batch_size\n","        )\n","\n","        pred_ans = []\n","        with torch.no_grad():\n","            for _, x_test in enumerate(test_loader):\n","                x = x_test[0].to(self.device).float()\n","\n","                y_pred = model(x).cpu().data.numpy()\n","                pred_ans.append(y_pred)\n","\n","        return np.concatenate(pred_ans).astype(\"float64\")\n","\n","    def input_from_feature_columns(self, X, feature_columns, embedding_dict, support_dense=True):\n","        sparse_feature_columns = list(\n","            filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n","\n","        dense_feature_columns = list(\n","            filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n","\n","        varlen_sparse_feature_columns = list(\n","            filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n","\n","        if not support_dense and len(dense_feature_columns) > 0:\n","            raise ValueError(\n","                \"DenseFeat is not supported in dnn_feature_columns\")\n","\n","        sparse_embedding_list = [embedding_dict[feat.embedding_name](\n","            X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]].long()) for\n","            feat in sparse_feature_columns]\n","\n","        varlen_sparse_embedding_list = get_varlen_pooling_list(embedding_dict, X, self.feature_index,\n","                                                               varlen_sparse_feature_columns, self.device)\n","\n","        dense_value_list = [X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]] for feat in\n","                            dense_feature_columns]\n","\n","        return sparse_embedding_list + varlen_sparse_embedding_list, dense_value_list\n","\n","    def compute_input_dim(self, feature_columns, include_sparse=True, include_dense=True, feature_group=False):\n","        sparse_feature_columns = list(\n","            filter(lambda x: isinstance(x, (SparseFeat, VarLenSparseFeat)), feature_columns)) if len(\n","            feature_columns) else []\n","        dense_feature_columns = list(\n","            filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n","\n","        dense_input_dim = sum(\n","            map(lambda x: x.dimension, dense_feature_columns))\n","        if feature_group:\n","            sparse_input_dim = len(sparse_feature_columns)\n","        else:\n","            sparse_input_dim = sum(feat.embedding_dim for feat in sparse_feature_columns)\n","        input_dim = 0\n","        if include_sparse:\n","            input_dim += sparse_input_dim\n","        if include_dense:\n","            input_dim += dense_input_dim\n","        return input_dim\n","\n","    def add_regularization_weight(self, weight_list, l1=0.0, l2=0.0):\n","        if isinstance(weight_list, torch.nn.parameter.Parameter):\n","            weight_list = [weight_list]\n","        else:\n","            weight_list = list(weight_list)\n","        self.regularization_weight.append((weight_list, l1, l2))\n","\n","    def get_regularization_loss(self):\n","        total_reg_loss = torch.zeros((1,), device=self.device)\n","        for weight_list, l1, l2 in self.regularization_weight:\n","            for w in weight_list:\n","                if isinstance(w, tuple):\n","                    parameter = w[1]  # named_parameters\n","                else:\n","                    parameter = w\n","                if l1 > 0:\n","                    total_reg_loss += torch.sum(l1 * torch.abs(parameter))\n","                if l2 > 0:\n","                    try:\n","                        total_reg_loss += torch.sum(l2 * torch.square(parameter))\n","                    except AttributeError:\n","                        total_reg_loss += torch.sum(l2 * parameter * parameter)\n","\n","        return total_reg_loss\n","\n","    def add_auxiliary_loss(self, aux_loss, alpha):\n","        self.aux_loss = aux_loss * alpha\n","\n","    def compile(self, optimizer, loss=None, metrics=None):\n","        self.metrics_names = [\"loss\"]\n","        self.optim = self._get_optim(optimizer)\n","        self.loss_func = self._get_loss_func(loss)\n","        self.metrics = self._get_metrics(metrics)\n","\n","    def _get_optim(self, optimizer):\n","        if isinstance(optimizer, str):\n","            if optimizer == \"sgd\":\n","                optim = torch.optim.SGD(self.parameters(), lr=0.01)\n","            elif optimizer == \"adam\":\n","                optim = torch.optim.Adam(self.parameters())  # 0.001\n","            elif optimizer == \"adagrad\":\n","                optim = torch.optim.Adagrad(self.parameters())  # 0.01\n","            elif optimizer == \"rmsprop\":\n","                optim = torch.optim.RMSprop(self.parameters())\n","            else:\n","                raise NotImplementedError\n","        else:\n","            optim = optimizer\n","        return optim\n","\n","    def _get_loss_func(self, loss):\n","        if isinstance(loss, str):\n","            if loss == \"binary_crossentropy\":\n","                loss_func = F.binary_cross_entropy\n","            elif loss == \"mse\":\n","                loss_func = F.mse_loss\n","            elif loss == \"mae\":\n","                loss_func = F.l1_loss\n","            else:\n","                raise NotImplementedError\n","        else:\n","            loss_func = loss\n","        return loss_func\n","\n","    def _log_loss(self, y_true, y_pred, eps=1e-7, normalize=True, sample_weight=None, labels=None):\n","        # change eps to improve calculation accuracy\n","        return log_loss(y_true,\n","                        y_pred,\n","                        eps,\n","                        normalize,\n","                        sample_weight,\n","                        labels)\n","\n","    def _get_metrics(self, metrics, set_eps=False):\n","        metrics_ = {}\n","        if metrics:\n","            for metric in metrics:\n","                if metric == \"binary_crossentropy\" or metric == \"logloss\":\n","                    if set_eps:\n","                        metrics_[metric] = self._log_loss\n","                    else:\n","                        metrics_[metric] = log_loss\n","                if metric == \"auc\":\n","                    metrics_[metric] = roc_auc_score\n","                if metric == \"mse\":\n","                    metrics_[metric] = mean_squared_error\n","                if metric == \"accuracy\" or metric == \"acc\":\n","                    metrics_[metric] = lambda y_true, y_pred: accuracy_score(\n","                        y_true, np.where(y_pred > 0.5, 1, 0))\n","                self.metrics_names.append(metric)\n","        return metrics_\n","\n","    @property\n","    def embedding_size(self):\n","        feature_columns = self.dnn_feature_columns\n","        sparse_feature_columns = list(\n","            filter(lambda x: isinstance(x, (SparseFeat, VarLenSparseFeat)), feature_columns)) if len(\n","            feature_columns) else []\n","        embedding_size_set = set([feat.embedding_dim for feat in sparse_feature_columns])\n","        if len(embedding_size_set) > 1:\n","            raise ValueError(\"embedding_dim of SparseFeat and VarlenSparseFeat must be same in this model!\")\n","        return list(embedding_size_set)[0]"],"metadata":{"id":"0OYN2KyhLVE4","executionInfo":{"status":"ok","timestamp":1644472564175,"user_tz":-180,"elapsed":1671,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["class DSSM(BaseTower):\n","    \"\"\"DSSM twin tower model\"\"\"\n","    def __init__(self, user_dnn_feature_columns, item_dnn_feature_columns, gamma=1, dnn_use_bn=True,\n","                 dnn_hidden_units=(300, 300, 128), dnn_activation='relu', l2_reg_dnn=0, l2_reg_embedding=1e-6,\n","                 dnn_dropout=0, init_std=0.0001, seed=1024, task='binary', device='cpu', gpus=None):\n","        super(DSSM, self).__init__(user_dnn_feature_columns, item_dnn_feature_columns,\n","                                    l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,\n","                                    device=device, gpus=gpus)\n","\n","        if len(user_dnn_feature_columns) > 0:\n","            self.user_dnn = DNN(compute_input_dim(user_dnn_feature_columns), dnn_hidden_units,\n","                                activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout,\n","                                use_bn=dnn_use_bn, init_std=init_std, device=device)\n","            self.user_dnn_embedding = None\n","\n","        if len(item_dnn_feature_columns) > 0:\n","            self.item_dnn = DNN(compute_input_dim(item_dnn_feature_columns), dnn_hidden_units,\n","                                activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout,\n","                                use_bn=dnn_use_bn, init_std=init_std, device=device)\n","            self.item_dnn_embedding = None\n","\n","        self.gamma = gamma\n","        self.l2_reg_embedding = l2_reg_embedding\n","        self.seed = seed\n","        self.task = task\n","        self.device = device\n","        self.gpus = gpus\n","\n","    def forward(self, inputs):\n","        if len(self.user_dnn_feature_columns) > 0:\n","            user_sparse_embedding_list, user_dense_value_list = \\\n","                self.input_from_feature_columns(inputs, self.user_dnn_feature_columns, self.user_embedding_dict)\n","\n","            user_dnn_input = combined_dnn_input(user_sparse_embedding_list, user_dense_value_list)\n","            self.user_dnn_embedding = self.user_dnn(user_dnn_input)\n","\n","        if len(self.item_dnn_feature_columns) > 0:\n","            item_sparse_embedding_list, item_dense_value_list = \\\n","                self.input_from_feature_columns(inputs, self.item_dnn_feature_columns, self.item_embedding_dict)\n","\n","            item_dnn_input = combined_dnn_input(item_sparse_embedding_list, item_dense_value_list)\n","            self.item_dnn_embedding = self.item_dnn(item_dnn_input)\n","\n","        if len(self.user_dnn_feature_columns) > 0 and len(self.item_dnn_feature_columns) > 0:\n","            score = Cosine_Similarity(self.user_dnn_embedding, self.item_dnn_embedding, gamma=self.gamma)\n","            output = self.out(score)\n","            return output\n","\n","        elif len(self.user_dnn_feature_columns) > 0:\n","            return self.user_dnn_embedding\n","\n","        elif len(self.item_dnn_feature_columns) > 0:\n","            return self.item_dnn_embedding\n","\n","        else:\n","            raise Exception(\"input Error! user and item feature columns are empty.\")"],"metadata":{"id":"Za631YWxliDT","executionInfo":{"status":"ok","timestamp":1644472572903,"user_tz":-180,"elapsed":269,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["data_path"],"metadata":{"id":"hiIQNW-lNGIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# service functions\n","def data_process(data_path, samp_rows=10000):\n","    data = pd.read_csv(data_path, nrows=samp_rows)\n","    data['rating'] = data['rating'].apply(lambda x: 1 if x > 3 else 0)\n","    data = data.sort_values(by='timestamp', ascending=True)\n","    train = data.iloc[:int(len(data)*0.8)].copy()\n","    test = data.iloc[int(len(data)*0.8):].copy()\n","    return train, test, data\n","\n","\n","def get_user_feature(data):\n","    data_group = data[data['rating'] == 1]\n","    data_group = data_group[['user_id', 'movie_id']].groupby('user_id').agg(list).reset_index()\n","    data_group['user_hist'] = data_group['movie_id'].apply(lambda x: '|'.join([str(i) for i in x]))\n","    data = pd.merge(data_group.drop('movie_id', axis=1), data, on='user_id')\n","    data_group = data[['user_id', 'rating']].groupby('user_id').agg('mean').reset_index()\n","    data_group.rename(columns={'rating': 'user_mean_rating'}, inplace=True)\n","    data = pd.merge(data_group, data, on='user_id')\n","    return data\n","\n","\n","def get_item_feature(data):\n","    data_group = data[['movie_id', 'rating']].groupby('movie_id').agg('mean').reset_index()\n","    data_group.rename(columns={'rating': 'item_mean_rating'}, inplace=True)\n","    data = pd.merge(data_group, data, on='movie_id')\n","    return data\n","\n","\n","def get_var_feature(data, col):\n","    key2index = {}\n","\n","    def split(x):\n","        key_ans = x.split('|')\n","        for key in key_ans:\n","            if key not in key2index:\n","                # Notice : input value 0 is a special \"padding\",\\\n","                # so we do not use 0 to encode valid feature for sequence input\n","                key2index[key] = len(key2index) + 1\n","        return list(map(lambda x: key2index[x], key_ans))\n","\n","    var_feature = list(map(split, data[col].values))\n","    var_feature_length = np.array(list(map(len, var_feature)))\n","    max_len = max(var_feature_length)\n","    var_feature = pad_sequences(var_feature, maxlen=max_len, padding='post', )\n","    return key2index, var_feature, max_len\n","\n","\n","def get_test_var_feature(data, col, key2index, max_len):\n","    print(\"user_hist_list: \\n\")\n","\n","    def split(x):\n","        key_ans = x.split('|')\n","        for key in key_ans:\n","            if key not in key2index:\n","                # Notice : input value 0 is a special \"padding\",\n","                # so we do not use 0 to encode valid feature for sequence input\n","                key2index[key] = len(key2index) + 1\n","        return list(map(lambda x: key2index[x], key_ans))\n","\n","    test_hist = list(map(split, data[col].values))\n","    test_hist = pad_sequences(test_hist, maxlen=max_len, padding='post')\n","    return test_hist\n","\n","\n"],"metadata":{"id":"ekykp3NHOwCR","executionInfo":{"status":"ok","timestamp":1644472634142,"user_tz":-180,"elapsed":4,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["data_path = \"/content/squad-v2.0.json\""],"metadata":{"id":"Al8aBnqxNYsl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%\n","data_path = './data/movielens.txt'\n","train, test, data = data_process(data_path, samp_rows=10000)\n","train = get_user_feature(train)\n","train = get_item_feature(train)\n","\n","sparse_features = ['user_id', 'movie_id', 'gender', 'age', 'occupation']\n","dense_features = ['user_mean_rating', 'item_mean_rating']\n","target = ['rating']\n","\n","user_sparse_features, user_dense_features = ['user_id', 'gender', 'age', 'occupation'], ['user_mean_rating']\n","item_sparse_features, item_dense_features = ['movie_id', ], ['item_mean_rating']\n","\n","# 1.Label Encoding for sparse features,and process sequence features\n","for feat in sparse_features:\n","    lbe = LabelEncoder()\n","    lbe.fit(data[feat])\n","    train[feat] = lbe.transform(train[feat])\n","    test[feat] = lbe.transform(test[feat])\n","mms = MinMaxScaler(feature_range=(0, 1))\n","mms.fit(train[dense_features])\n","train[dense_features] = mms.transform(train[dense_features])\n","\n","# 2.preprocess the sequence feature\n","genres_key2index, train_genres_list, genres_maxlen = get_var_feature(train, 'genres')\n","user_key2index, train_user_hist, user_maxlen = get_var_feature(train, 'user_hist')\n","\n","user_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4)\n","                        for i, feat in enumerate(user_sparse_features)] + [DenseFeat(feat, 1, ) for feat in\n","                                                                            user_dense_features]\n","item_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4)\n","                        for i, feat in enumerate(item_sparse_features)] + [DenseFeat(feat, 1, ) for feat in\n","                                                                            item_dense_features]\n","\n","item_varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres', vocabulary_size=1000, embedding_dim=4),\n","                                                maxlen=genres_maxlen, combiner='mean', length_name=None)]\n","\n","user_varlen_feature_columns = [VarLenSparseFeat(SparseFeat('user_hist', vocabulary_size=3470, embedding_dim=4),\n","                                                maxlen=user_maxlen, combiner='mean', length_name=None)]\n","\n","# 3.generate input data for model\n","user_feature_columns += user_varlen_feature_columns\n","item_feature_columns += item_varlen_feature_columns\n","\n","# add user history as user_varlen_feature_columns\n","train_model_input = {name: train[name] for name in sparse_features + dense_features}\n","train_model_input[\"genres\"] = train_genres_list\n","train_model_input[\"user_hist\"] = train_user_hist\n","\n","# %%\n","# 4.Define Model,train,predict and evaluate\n","device = 'cpu'\n","use_cuda = True\n","if use_cuda and torch.cuda.is_available():\n","    print('cuda ready...')\n","    device = 'cuda:0'\n","\n","model = DSSM(user_feature_columns, item_feature_columns, task='binary', device=device)\n","\n","model.compile(\"adam\", \"binary_crossentropy\", metrics=['auc', 'accuracy'])\n","\n","# %%\n","model.fit(train_model_input, train[target].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)\n","# model.save\n","\n","# %%\n","# 5.preprocess the test data\n","test = pd.merge(test, train[['movie_id', 'item_mean_rating']].drop_duplicates(), on='movie_id', how='left').fillna(\n","    0.5)\n","test = pd.merge(test, train[['user_id', 'user_mean_rating']].drop_duplicates(), on='user_id', how='left').fillna(\n","    0.5)\n","test = pd.merge(test, train[['user_id', 'user_hist']].drop_duplicates(), on='user_id', how='left').fillna('1')\n","test[dense_features] = mms.transform(test[dense_features])\n","\n","test_genres_list = get_test_var_feature(test, 'genres', genres_key2index, genres_maxlen)\n","test_user_hist = get_test_var_feature(test, 'user_hist', user_key2index, user_maxlen)\n","\n","test_model_input = {name: test[name] for name in sparse_features + dense_features}\n","test_model_input[\"genres\"] = test_genres_list\n","test_model_input[\"user_hist\"] = test_user_hist\n","\n","# %%\n","# 6.Evaluate\n","eval_tr = model.evaluate(train_model_input, train[target].values)\n","print(eval_tr)\n","\n","# %%\n","pred_ts = model.predict(test_model_input, batch_size=2000)\n","print(\"test LogLoss\", round(log_loss(test[target].values, pred_ts), 4))\n","print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ts), 4))\n","\n","# %%\n","# 7.Embedding\n","print(\"user embedding shape: \", model.user_dnn_embedding[:2])\n","print(\"item embedding shape: \", model.item_dnn_embedding[:2])\n","\n","# %%\n","# 8. get single tower\n","dict_trained = model.state_dict()    # trained model\n","trained_lst = list(dict_trained.keys())\n","\n","# user tower\n","model_user = DSSM(user_feature_columns, [], task='binary', device=device)\n","dict_user = model_user.state_dict()\n","for key in dict_user:\n","    dict_user[key] = dict_trained[key]\n","model_user.load_state_dict(dict_user)    # load trained model parameters of user tower\n","user_feature_name = user_sparse_features + user_dense_features\n","user_model_input = {name: test[name] for name in user_feature_name}\n","user_model_input[\"user_hist\"] = test_user_hist\n","user_embedding = model_user.predict(user_model_input, batch_size=2000)\n","print(\"single user embedding shape: \", user_embedding[:2])\n","\n","# item tower\n","model_item = DSSM([], item_feature_columns, task='binary', device=device)\n","dict_item = model_item.state_dict()\n","for key in dict_item:\n","    dict_item[key] = dict_trained[key]\n","model_item.load_state_dict(dict_item)  # load trained model parameters of item tower\n","item_feature_name = item_sparse_features + item_dense_features\n","item_model_input = {name: test[name] for name in item_feature_name}\n","item_model_input[\"genres\"] = test_genres_list\n","item_embedding = model_item.predict(item_model_input, batch_size=2000)\n","print(\"single item embedding shape: \", item_embedding[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"42zQr5iONRNN","executionInfo":{"status":"error","timestamp":1644472639409,"user_tz":-180,"elapsed":666,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}},"outputId":"f159a375-2deb-4897-8a80-a11c904784da"},"execution_count":56,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-3e9eec30ba3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/movielens.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_item_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-55-9d23131888bd>\u001b[0m in \u001b[0;36mdata_process\u001b[0;34m(data_path, samp_rows)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# service functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamp_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/movielens.txt'"]}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"Upf0vSJqzvDl"},"source":["### Training: loss function (3 points)\n"]},{"cell_type":"markdown","metadata":{"id":"zAxDxnGrzvDr"},"source":["### Training loop (4 points)"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"BdbIN9MFzvDr"},"source":["For a difference, we'll ask __you__ to implement training loop this time.\n","\n","Here's a sketch of one epoch:\n","1. iterate over __`batches_per_epoch`__ batches from __`train_data`__ with __`iterate_minibatches`__\n","    * Compute loss, backprop, optimize\n","    * Compute and accumulate recall\n","    \n","2. iterate over __`batches_per_epoch`__ batches from __`val_data`__\n","    * Compute and accumulate recall\n","    \n","3. print stuff :)\n"]},{"cell_type":"code","metadata":{"id":"PaXlxhxVzvDs","executionInfo":{"status":"aborted","timestamp":1644472391610,"user_tz":-180,"elapsed":28,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["num_epochs = 100\n","max_len = 100\n","batch_size = 32\n","batches_per_epoch = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tet-fHLqzvDt","executionInfo":{"status":"aborted","timestamp":1644472391611,"user_tz":-180,"elapsed":28,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMJRQQ2TzvDu","executionInfo":{"status":"aborted","timestamp":1644472391612,"user_tz":-180,"elapsed":29,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hnRFaPT-zvDw","executionInfo":{"status":"aborted","timestamp":1644472391613,"user_tz":-180,"elapsed":30,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rD3deRdzvDx"},"source":["### Evaluation\n","\n","Let's see how our model performs on actual question answering. You will score answer candidates with your model and select the most appropriate one.\n","\n","__Your goal__ is to obtain accuracy of at least above 50%. Beating 65% in this notebook yields bonus points :)"]},{"cell_type":"code","metadata":{"id":"ziEOqbLgzvDx","executionInfo":{"status":"aborted","timestamp":1644472391614,"user_tz":-180,"elapsed":30,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["# optional: prepare some functions here\n","# <...>\n","\n","def select_best_answer(question, possible_answers):\n","    \"\"\"\n","    Predicts which answer best fits the question\n","    :param question: a single string containing a question\n","    :param possible_answers: a list of strings containing possible answers\n","    :returns: integer - the index of best answer in possible_answer\n","    \"\"\"\n","    <YOUR CODE>\n","    return <...>\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVgvCo1ozvDy","executionInfo":{"status":"aborted","timestamp":1644472391615,"user_tz":-180,"elapsed":31,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["predicted_answers = [\n","    select_best_answer(question, possible_answers)\n","    for i, (question, possible_answers) in tqdm(test[['question', 'options']].iterrows(), total=len(test))\n","]\n","\n","accuracy = np.mean([\n","    answer in correct_ix\n","    for answer, correct_ix in zip(predicted_answers, test['correct_indices'].values)\n","])\n","print(\"Accuracy: %0.5f\" % accuracy)\n","assert accuracy > 0.65, \"we need more accuracy!\"\n","print(\"Great job!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IIqvG1udaVwM"},"source":[""]},{"cell_type":"code","metadata":{"id":"cEOheIsyzvDz","executionInfo":{"status":"aborted","timestamp":1644472391617,"user_tz":-180,"elapsed":33,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["def draw_results(question, possible_answers, predicted_index, correct_indices):\n","    print(\"Q:\", question, end='\\n\\n')\n","    for i, answer in enumerate(possible_answers):\n","        print(\"#%i: %s %s\" % (i, '[*]' if i == predicted_index else '[ ]', answer))\n","    \n","    print(\"\\nVerdict:\", \"CORRECT\" if predicted_index in correct_indices else \"INCORRECT\", \n","          \"(ref: %s)\" % correct_indices, end='\\n' * 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYJS6w6kzvD0","executionInfo":{"status":"aborted","timestamp":1644472391618,"user_tz":-180,"elapsed":33,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["for i in [1, 100, 1000, 2000, 3000, 4000, 5000]:\n","    draw_results(test.iloc[i].question, test.iloc[i].options,\n","                 predicted_answers[i], test.iloc[i].correct_indices)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9R8hFOwPzvD1","executionInfo":{"status":"aborted","timestamp":1644472391619,"user_tz":-180,"elapsed":34,"user":{"displayName":"Vladislav Melnichuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3F7nSpPnFoXxL_fPnQxVBeJp7KojsNed_OL2toQ=s64","userId":"12987108233979345356"}}},"source":["question = \"What is my name?\" # your question here!\n","possible_answers = [\n","    <...> \n","    # ^- your options. \n","]\n","predicted answer = select_best_answer(question, possible_answers)\n","\n","draw_results(question, possible_answers,\n","             predicted_answer, [0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"RAmhaEaFzvD2"},"source":["### Bonus tasks\n","\n","There are many ways to improve our question answering model. Here's a bunch of things you can do to increase your understanding and get bonus points.\n","\n","\n","### 0. Fine-tuning (3+ pts)\n","This time our dataset is fairly small. We can improve the training procedure by starting with a pre-trained model.\n","* The simplest option is to use pre-trained embeddings. See previous weeks for that.\n","* A harder (but better) alternative is to use a pre-trained sentence encoder. Consider [InferSent](https://github.com/facebookresearch/InferSent), Universal Sentence Encoder or ELMO.\n","\n","\n","### 1.  Hard Negatives (3+ pts)\n","\n","Not all wrong answers are equally wrong. As the training progresses, _most negative examples $a^-$ will be to easy._ So easy in fact, that loss function and gradients on such negatives is exactly __0.0__. To improve training efficiency, one can __mine hard negative samples__.\n","\n","Given a list of answers,\n","* __Hard negative__ is the wrong answer with highest similarity with question,\n","\n","$$a^-_{hard} = \\underset {a^-} {argmax} \\space sim[V_q(q), V_a(a^-)]$$\n","\n","* __Semi-hard negative__ is the one with highest similarity _among wrong answers that are farther than positive one. This option is more useful if some wrong answers may actually be mislabelled correct answers.\n","\n","* One can also __sample__ negatives proportionally to $$P(a^-_i) \\sim e ^ {sim[V_q(q), V_a(a^-_i)]}$$\n","\n","\n","The task is to implement at least __hard negative__ sampling and apply it for model training.\n","\n","\n","### 2. Bring Your Own Model (3+ pts)\n","In addition to Universal Sentence Encoder, one can also train a new model.\n","* You name it: convolutions, RNN, self-attention\n","* Use pre-trained ELMO or FastText embeddings\n","* Monitor overfitting and use dropout / word dropout to improve performance\n","\n","__Note:__ if you use ELMO please note that it requires tokenized text while USE can deal with raw strings. You can tokenize data manually or use tokenized=True when reading dataset.\n","\n","\n","* hard negatives (strategies: hardest, hardest farter than current, randomized)\n","* train model on the full dataset to see if it can mine answers to new questions over the entire wikipedia. Use approximate nearest neighbor search for fast lookup.\n","\n","\n","### 3. Search engine (3+ pts)\n","\n","Our basic model only selects answers from 2-5 available sentences in paragraph. You can extend it to search over __the whole dataset__. All sentences in all other paragraphs are viable answers.\n","\n","The goal is to train such a model and use it to __quickly find top-10 answers from the whole set__.\n","\n","* You can ask such model a question of your own making - to see which answers it can find among the entire training dataset or even the entire wikipedia.\n","* Searching for top-K neighbors is easier if you use specialized methods: [KD-Tree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html) or [HNSW](https://github.com/nmslib/hnswlib). \n","* This task is much easier to train if you use hard or semi-hard negatives. You can even find hard negatives for one question from correct answers to other questions in batch - do so in-graph for maximum efficiency. See [1.] for more details.\n"]},{"cell_type":"markdown","source":["# **Выводы:**\n","\n","1. Обучил DSSM сеть для ответа цитатами (предложениями) из текста по вопросу пользователя.\n","2.  \n","\n","1. Обучил seq2seq для перевода c **English** на **Spain**.\n","2. Решил проблему неизвестных слов с помощью **bpe токенайзера** (byte-pair).\n","3. Провел ряд экспериментов, оказалось, что с TeacherForcing (**TF**) = **1.0** loss = **0.596**, TF = **0.5** loss = **0.826**, **TF** = **0.0** loss = **0.973**.\n","4. Провел ряд экспериментов, оказалось, что **с Attention** и TF=1.0 loss = **0.596**, **без Attention** loss = **0.618**.\n","\n","**Итог:** \n","1. Teacher Forcing улучшает точность модели в разы, лучше его использовать всегда.\n","2. C Attention сеть работает лучше.\n","\n","**Off-topic** (будущие улучшения):\n","1. Заменил embeddings with pre-trained word embeddings **word2vec** или GloVe.\n","2. улучшить распознавание неизвестных слов с помощью VAE подбирать наиболее близкое по вектору"],"metadata":{"id":"Kfv2I55hQMDj"}}]}